{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#welcome-to-database-helper","title":"Welcome to Database Helper","text":""},{"location":"#youtube","title":"Youtube","text":""},{"location":"#introduction","title":"Introduction","text":"<ul> <li>7 Database Paradigms</li> <li>How To Choose The Right Database?</li> <li>SQL vs NoSQL or MySQL vs MongoDB</li> <li>Which Is Better? SQL vs NoSQL</li> <li>Database Design Tips | Choosing the Best Database in a System Design Interview</li> <li>15 futuristic databases you've never heard of</li> <li>What is Database Sharding?</li> <li>When should you shard your database?</li> <li>Which Database Model to Choose?</li> <li>Secret To Optimizing SQL Queries - Understand The SQL Execution Order</li> </ul>"},{"location":"#database","title":"Database","text":"<ul> <li>w3schools</li> <li>Complete DBMS Course</li> <li>SQL Course</li> <li>Databases in Depth</li> <li>Database Programming from scratch</li> <li>DBMS Placements Series</li> <li>Database Tutorials</li> <li>Database in kubernetes</li> <li>Database Engineering</li> <li>Relational database (RDBMS) by Decomplexify</li> </ul>"},{"location":"#sql","title":"SQL","text":"<ul> <li>SQL Tutorial - Full Database Course for Beginners</li> </ul>"},{"location":"#postgresql","title":"PostgreSQL","text":""},{"location":"#nosql","title":"NOSQL","text":"<ul> <li>How do NoSQL databases work? Simply Explained!</li> <li>The Secret Sauce Behind NoSQL: LSM Tree</li> <li>Cassandra vs MongoDB vs HBase | Difference Between Popular NoSQL Databases | Edureka</li> </ul>"},{"location":"#graph-database","title":"Graph database","text":"<ul> <li>Graph Databases Will Change Your Freakin' Life (Best Intro Into Graph Databases)</li> </ul>"},{"location":"#vector-database","title":"Vector database","text":"<ul> <li>The Power of Vector Databases For Knowledge Search</li> <li>Vector databases are so hot right now. WTF are they?</li> </ul>"},{"location":"#dbmsiit","title":"DBMS(IIT)","text":"<ul> <li>Data Base Management System | IIT-KGP</li> <li>Database Management Systems | IIT-MADRAS</li> </ul>"},{"location":"#udemy","title":"Udemy","text":""},{"location":"#introduction_1","title":"Introduction","text":"<ul> <li>Cloud Computing for Beginners - Database Technologies</li> <li>Relational Database Design</li> </ul>"},{"location":"#dbms","title":"DBMS","text":"<ul> <li>Fundamentals of Database Engineering</li> <li>Database Management System from scratch in parts<ul> <li>Database Management System from scratch - Part 1</li> <li>Database Management System from scratch - Part 2</li> <li>Database Management Systems Part 3 : SQL Interview Course</li> <li>Database Management Systems Part 4 : Transactions</li> <li>Database Management Final Part (5): Indexing,B Trees,B+Trees</li> </ul> </li> <li>Complete SQL and Databases Bootcamp</li> </ul>"},{"location":"#blogs","title":"Blogs","text":""},{"location":"#introduction_2","title":"Introduction","text":"<ul> <li>Strong Consistency vs Eventual Consistency</li> <li>6 Reasons Why PostgreSQL is Not So Popular, Yet!</li> <li>Why MongoDB is Still Popular?</li> <li>LSM Trees: the Go-To Data Structure for Databases, Search Engines, and More</li> <li>Optimistic Locking vs Pessimistic Locking: Managing Concurrent Access</li> <li>Redis Pub-Sub or Kafka: Choosing the Right Tool for Your Use Case</li> <li>Understand the basic Kafka architecture before you go crazy with it!</li> <li>The Simplified Introduction of Vector Databases</li> <li>SSTables and LSM Trees</li> <li>B-Trees</li> <li>Concurrency Challenges in Database Transactions: Isolation Levels and Locking Mechanisms</li> <li>Hash Indexing</li> <li>Leaderless Replication In Distributed System</li> <li>Understanding Database Partitioning in Distributed Systems : Rebalancing Partitions</li> <li>Introduction To Database Indexing</li> <li>Design Metrics Aggregation System | LSM Tree | Storage Engine</li> </ul>"},{"location":"#sql_1","title":"SQL","text":"<ul> <li>SQL Fundamentals<ul> <li>20 Advanced SQL Techniques</li> <li>9 Advanced SQL Queries for Data Mastery</li> <li>Top 10 Advanced SQL Queries</li> </ul> </li> <li>Learning SQL<ul> <li>Writing SQL Like a Pro: Advanced Techniques Showcased in a Real-Life Scenario</li> <li>12 Tips for Optimizing SQL Queries for Faster Performance</li> </ul> </li> <li>Dev Genius<ul> <li>9 SQL Mistakes to Avoid for Effective Queries </li> </ul> </li> </ul>"},{"location":"kafka/links/","title":"links","text":""},{"location":"kafka/links/#kafka-basics","title":"Kafka basics","text":""},{"location":"kafka/links/#youtube","title":"Youtube","text":""},{"location":"kafka/links/#introduction","title":"Introduction","text":"<ul> <li>System Design: Apache Kafka In 3 Minutes</li> <li>System Design: Why is Kafka fast?</li> <li>Apache Kafka vs message queue explained</li> <li>What is a Message Queue and When should you use Messaging Queue Systems Like RabbitMQ and Kafka</li> </ul>"},{"location":"kafka/links/#courses","title":"Courses","text":"<ul> <li>Apache Kafka Crash Course | What is Kafka? | Piyush Garg</li> <li>Kafka for beginners | Java Techie</li> <li>Course | Apache Kafka Fundamentals | Confluent</li> <li>Kafka Architecture in Depth | Apache Kafka Architecture | Understanding Kafka Architecture | DataCouch</li> <li>Exploring Kafka Internals | Kafka | DataCouch</li> <li>Confluent</li> <li>Microservices 101</li> <li>Kafka Streams Tutorials | Kafka Streams 101 (2023)</li> </ul>"},{"location":"kafka/links/#udemy","title":"Udemy","text":"<ul> <li>Apache Kafka for absolute beginners</li> <li>Java Microservices: CQRS &amp; Event Sourcing with Kafka</li> <li>Apache Kafka Series - Learn Apache Kafka for Beginners v3</li> </ul>"},{"location":"mongodb/","title":"index","text":""},{"location":"mongodb/#introduction","title":"Introduction","text":"<p>Why Indexes?</p> <p>An index can speed up our find update and delete query. If our query is like <code>db.products.find({ seller : \"Max\" })</code> then MongoDB will search for the entire collection for the seller name <code>\"Max\"</code>, which is also called as <code>COLLSCAN</code> and this can take a while if there is million record. </p> <p>So, in that case we can create a <code>Index</code> on <code>Selle</code>r field. MongoDB will create an <code>Ordered</code> list with all the values of the <code>Seller</code>s and all the items of this list will have a pointer to the actual document in the collection.  Now if we run the exact query then Mongodb will see that there is an <code>Index</code> on Seller so MongoDB will run <code>IXSCAN</code> and directly jump to <code>\"M\"</code> which will speed up the querying.</p> <p>But we should not overdo the indexes. If we can index on all fields, then it will certainly improve the performance for the find query but for the <code>insert</code> query it will slow down. As now it will again have to update the Ordered list for every field index for every insert and update.</p> <p>To see the all the index present on the collection: </p><pre><code>&gt; db.infos.getIndexes()\n[ { \"v\" : 2, \"key\" : { \"_id\" : 1 }, \"name\" : \"_id_\" } ]\n</code></pre> <p>By default, mongodb will create an index on <code>_id</code> field. To create an index on specific fields: </p><pre><code>db.infos.createIndex( { \"dob.age\" : 1} } )\n\ndb.infos.createIndex( { \"dob.age\" : -1} } )\n</code></pre> <code>1</code> means increasing and <code>-1</code> means decreasing Though that does not matter as mongoDB can traverse both ways.  <p>We can also create index with more than on field. The order matters here. </p><pre><code>db.infos.createIndex( { \"email\" : 1, \"dob.age\" : 1} } )\n</code></pre> This means that mongoDb will create a <code>compound index</code> and first the <code>index</code> with email then <code>dob.age</code> Example: (a@test.com,23) will come before (a.@test.com,24)  <p>To drop the index use: </p><pre><code>&gt;db.infos.dropIndex({ \"dob.age\": 1 })\n{ \"nIndexesWas\" : 2, \"ok\" : 1 }\n</code></pre> <p>We can also drop index by name.  </p><pre><code>&gt; db.infos.dropIndex(\"dob.age_1\")\n{ \"nIndexesWas\" : 2, \"ok\" : 1 }\n</code></pre>"},{"location":"mongodb/#query-explain","title":"Query Explain","text":"<p>To analyse how a query will execute mongodb has a unique method that is explain(). </p><pre><code>&gt; db.infos.explain().find( { \"dob.age\" : { $gt : 60 }} )\n{\n        \"explainVersion\" : \"1\",\n        \"queryPlanner\" : {\n                \"namespace\" : \"persons.infos\",\n                \"indexFilterSet\" : false,\n                \"parsedQuery\" : {\n                        \"dob.age\" : {\n                                \"$gt\" : 60\n                        }\n                },\n                \"queryHash\" : \"FC9E47D2\",\n                \"planCacheKey\" : \"A5FF588D\",\n                \"maxIndexedOrSolutionsReached\" : false,\n                \"maxIndexedAndSolutionsReached\" : false,\n                \"maxScansToExplodeReached\" : false,\n                \"winningPlan\" : {\n                        \"stage\" : \"COLLSCAN\",\n                        \"filter\" : {\n                                \"dob.age\" : {\n                                        \"$gt\" : 60\n                                }\n                        },\n                        \"direction\" : \"forward\"\n                },\n                \"rejectedPlans\" : [ ]\n        },\n        \"command\" : {\n                \"find\" : \"infos\",\n                \"filter\" : {\n                        \"dob.age\" : {\n                                \"$gt\" : 60\n                        }\n                },\n                \"$db\" : \"persons\"\n        },\n\n        \"ok\" : 1\n}\n</code></pre> <p>In the winning plan we can see <code>COLLSCAN</code> as mongodb searched the entire collection for this query. There is also a rejected plans array but currently it is empty as mongodb has no other option than searching the entire array.</p> <p>We can also add additional properties in explain(). It will print some additional information </p><pre><code>&gt; db.infos.explain(\"executionStats\").find( { \"dob.age\" : { $gt : 60 }} )\n{\n        \"explainVersion\" : \"1\",\n        \"queryPlanner\" : {\n                \"namespace\" : \"persons.infos\",\n                \"indexFilterSet\" : false,\n                \"parsedQuery\" : {\n                        \"dob.age\" : {\n                                \"$gt\" : 60\n                        }\n                },\n                \"maxIndexedOrSolutionsReached\" : false,\n                \"maxIndexedAndSolutionsReached\" : false,\n                \"maxScansToExplodeReached\" : false,\n                \"winningPlan\" : {\n                        \"stage\" : \"COLLSCAN\",\n                        \"filter\" : {\n                                \"dob.age\" : {\n                                        \"$gt\" : 60\n                                }\n                        },\n                        \"direction\" : \"forward\"\n                },\n                \"rejectedPlans\" : [ ]\n        },\n        \"executionStats\" : {\n                \"executionSuccess\" : true,\n                \"nReturned\" : 1222,\n                \"executionTimeMillis\" : 3,\n                \"totalKeysExamined\" : 0,\n                \"totalDocsExamined\" : 5000,\n                \"executionStages\" : {\n                        \"stage\" : \"COLLSCAN\",\n                        \"filter\" : {\n                                \"dob.age\" : {\n                                        \"$gt\" : 60\n                                }\n                        },\n                        \"nReturned\" : 1222,\n                        \"executionTimeMillisEstimate\" : 0,\n                        \"works\" : 5002,\n                        \"advanced\" : 1222,\n                        \"needTime\" : 3779,\n                        \"needYield\" : 0,\n                        \"saveState\" : 5,\n                        \"restoreState\" : 5,\n                        \"isEOF\" : 1,\n                        \"direction\" : \"forward\",\n                        \"docsExamined\" : 5000\n                }\n        },\n        \"command\" : {\n                \"find\" : \"infos\",\n                \"filter\" : {\n                        \"dob.age\" : {\n                                \"$gt\" : 60\n                        }\n                },\n                \"$db\" : \"persons\"\n        },\n\n        \"ok\" : 1\n}\n</code></pre> <p>Here we can see some other additional informations like totalDocumentScan, totalDocumentReturn, executionTimeMillis.</p> <p>Now if we do the indexing on dob.age and run the same query with explain </p><pre><code>&gt; db.infos.createIndex( { \"dob.age\" : 1} )\n{\n        \"numIndexesBefore\" : 1,\n        \"numIndexesAfter\" : 2,\n        \"createdCollectionAutomatically\" : false,\n        \"ok\" : 1\n}\n\n&gt; db.infos.explain(\"executionStats\").find( { \"dob.age\" : { $gt : 60 }} )\n{\n        \"explainVersion\" : \"1\",\n        \"queryPlanner\" : {\n                \"namespace\" : \"persons.infos\",\n                \"indexFilterSet\" : false,\n                \"parsedQuery\" : {\n                        \"dob.age\" : {\n                                \"$gt\" : 60\n                        }\n                },\n                \"maxIndexedOrSolutionsReached\" : false,\n                \"maxIndexedAndSolutionsReached\" : false,\n                \"maxScansToExplodeReached\" : false,\n                \"winningPlan\" : {\n                        \"stage\" : \"FETCH\",\n                        \"inputStage\" : {\n                                \"stage\" : \"IXSCAN\",\n                                \"keyPattern\" : {\n                                        \"dob.age\" : 1\n                                },\n                                \"indexName\" : \"dob.age_1\",\n                                \"isMultiKey\" : false,\n                                \"multiKeyPaths\" : {\n                                        \"dob.age\" : [ ]\n                                },\n                                \"isUnique\" : false,\n                                \"isSparse\" : false,\n                                \"isPartial\" : false,\n                                \"indexVersion\" : 2,\n                                \"direction\" : \"forward\",\n                                \"indexBounds\" : {\n                                        \"dob.age\" : [\n                                                \"(60.0, inf.0]\"\n                                        ]\n                                }\n                        }\n                },\n                \"rejectedPlans\" : [ ]\n        },\n        \"executionStats\" : {\n                \"executionSuccess\" : true,\n                \"nReturned\" : 1222,\n                \"executionTimeMillis\" : 50,\n                \"totalKeysExamined\" : 1222,\n                \"totalDocsExamined\" : 1222,\n                \"executionStages\" : {\n                        \"stage\" : \"FETCH\",\n                        \"nReturned\" : 1222,\n                        \"executionTimeMillisEstimate\" : 0,\n                        \"works\" : 1223,\n                        \"advanced\" : 1222,\n                        \"needTime\" : 0,\n                        \"needYield\" : 0,\n                        \"saveState\" : 1,\n                        \"restoreState\" : 1,\n                        \"isEOF\" : 1,\n                        \"docsExamined\" : 1222,\n                        \"alreadyHasObj\" : 0,\n                        \"inputStage\" : {\n                                \"stage\" : \"IXSCAN\",\n                                \"nReturned\" : 1222,\n                                \"executionTimeMillisEstimate\" : 0,\n                                \"works\" : 1223,\n                                \"advanced\" : 1222,\n                                \"needTime\" : 0,\n                                \"needYield\" : 0,\n                                \"saveState\" : 1,\n                                \"restoreState\" : 1,\n                                \"isEOF\" : 1,\n                                \"keyPattern\" : {\n                                        \"dob.age\" : 1\n                                },\n                                \"indexName\" : \"dob.age_1\",\n                                \"isMultiKey\" : false,\n                                \"multiKeyPaths\" : {\n                                        \"dob.age\" : [ ]\n                                },\n                                \"isUnique\" : false,\n                                \"isSparse\" : false,\n                                \"isPartial\" : false,\n                                \"indexVersion\" : 2,\n                                \"direction\" : \"forward\",\n                                \"indexBounds\" : {\n                                        \"dob.age\" : [\n                                                \"(60.0, inf.0]\"\n                                        ]\n                                },\n                                \"keysExamined\" : 1222,\n                                \"seeks\" : 1,\n                                \"dupsTested\" : 0,\n                                \"dupsDropped\" : 0\n                        }\n                }\n        },\n        \"command\" : {\n                \"find\" : \"infos\",\n                \"filter\" : {\n                        \"dob.age\" : {\n                                \"$gt\" : 60\n                        }\n                },\n                \"$db\" : \"persons\"\n        },\n\n        \"ok\" : 1\n}\n</code></pre> Now the query did not search for the entire collection it has done an <code>IXSCAN</code>."},{"location":"mongodb/#indexes-behind-the-scenes","title":"Indexes Behind the Scenes","text":"<p>What does createIndex() do in detail?</p> <p>Whilst we can't really see the index, you can think of the index as a simple list of values + pointers to the original document. Something like this (for the \"age\" field):</p> <ul> <li>(29, \"address in memory/ collection a1\")</li> <li>(30, \"address in memory/ collection a2\")</li> <li>(33, \"address in memory/ collection a3\")</li> </ul> <p>The documents in the collection would be at the \"addresses\" a1, a2 and a3. The order does not have to match the order in the index (and most likely, it indeed won't).</p> <p>The important thing is that the index items are ordered (ascending or descending - depending on how you created the index). </p> <p><code>createIndex({age: 1})</code> creates an index with ascending sorting, <code>createIndex({age: -1})</code> creates one with descending sorting.</p> <p>MongoDB is now able to quickly find a fitting document when you filter for its age as it has a sorted list. Sorted lists are way quicker to search because you can skip entire ranges (and don't have to look at every single document).</p> <p>Additionally, sorting (via sort(...)) will also be sped up because you already have a sorted list. Of course, this is only true when sorting for the age.</p> <p>Let's say all our document has <code>age</code> greater than 50 and in query <code>[db.infos.find({\"dob.age\": { $gt: 20 }})]</code> we are trying to find the documents greater than <code>20</code> so it will return all the documents. So, in this case IXSCAN has the less performance as it will introduce an extra step. As at first the mongodb will scan the entire index then it will go to the actual mongodb collection. If we delete the index, then it will again search with COLSCAN and eventually that will have a better performance. So, it is recommended that only to use index when the query will return a <code>small subset</code> of the actual collection. </p> <p>Index on Boolean value does not make much sense.</p>"},{"location":"mongodb/#compound-index","title":"Compound index","text":"<p>first let's create a compound index </p><pre><code>&gt; db.infos.createIndex({ \"dob.age\" : 1, \"gender\" : 1})\n{\n    \"numIndexesBefore\" : 1,\n    \"numIndexesAfter\" : 2,\n    \"createdCollectionAutomatically\" : false,\n    \"ok\" : 1\n}\n</code></pre> <p>If we search with dob.age and gender then mongodb will use this compound index. </p><pre><code>&gt; db.infos.explain(\"executionStats\").find({\"dob.age\" : 35, \"gender\" : \"male\"})\n{\n        \"explainVersion\" : \"1\",\n        \"queryPlanner\" : {\n                \"namespace\" : \"persons.infos\",\n                \"indexFilterSet\" : false,\n                \"parsedQuery\" : {\n                        \"$and\" : [\n                                {\n                                        \"dob.age\" : {\n                                                \"$eq\" : 35\n                                        }\n                                },\n                                {\n                                        \"gender\" : {\n                                                \"$eq\" : \"male\"\n                                        }\n                                }\n                        ]\n                },\n                \"maxIndexedOrSolutionsReached\" : false,\n                \"maxIndexedAndSolutionsReached\" : false,\n                \"maxScansToExplodeReached\" : false,\n                \"winningPlan\" : {\n                        \"stage\" : \"FETCH\",\n                        \"inputStage\" : {\n                                \"stage\" : \"IXSCAN\",\n                                \"keyPattern\" : {\n                                        \"dob.age\" : 1,\n                                        \"gender\" : 1\n                                },\n                                \"indexName\" : \"dob.age_1_gender_1\",\n                                \"isMultiKey\" : false,\n                                \"multiKeyPaths\" : {\n                                        \"dob.age\" : [ ],\n                                        \"gender\" : [ ]\n                                },\n                                \"isUnique\" : false,\n                                \"isSparse\" : false,\n                                \"isPartial\" : false,\n                                \"indexVersion\" : 2,\n                                \"direction\" : \"forward\",\n                                \"indexBounds\" : {\n                                        \"dob.age\" : [\n                                                \"[35.0, 35.0]\"\n                                        ],\n                                        \"gender\" : [\n                                                \"[\\\"male\\\", \\\"male\\\"]\"\n                                        ]\n                                }\n                        }\n                },\n                \"rejectedPlans\" : [ ]\n        },\n        \"executionStats\" : {\n                \"executionSuccess\" : true,\n                \"nReturned\" : 43,\n                \"executionTimeMillis\" : 19,\n                \"totalKeysExamined\" : 43,\n                \"totalDocsExamined\" : 43,\n                \"executionStages\" : {\n                        \"stage\" : \"FETCH\",\n                        \"nReturned\" : 43,\n                        \"executionTimeMillisEstimate\" : 11,\n                        \"works\" : 44,\n                        \"advanced\" : 43,\n                        \"needTime\" : 0,\n                        \"needYield\" : 0,\n                        \"saveState\" : 1,\n                        \"restoreState\" : 1,\n                        \"isEOF\" : 1,\n                        \"docsExamined\" : 43,\n                        \"alreadyHasObj\" : 0,\n                        \"inputStage\" : {\n                                \"stage\" : \"IXSCAN\",\n                                \"nReturned\" : 43,\n                                \"executionTimeMillisEstimate\" : 11,\n                                \"works\" : 44,\n                                \"advanced\" : 43,\n                                \"needTime\" : 0,\n                                \"needYield\" : 0,\n                                \"saveState\" : 1,\n                                \"restoreState\" : 1,\n                                \"isEOF\" : 1,\n                                \"keyPattern\" : {\n                                        \"dob.age\" : 1,\n                                        \"gender\" : 1\n                                },\n                                \"indexName\" : \"dob.age_1_gender_1\",\n                                \"isMultiKey\" : false,\n                                \"multiKeyPaths\" : {\n                                        \"dob.age\" : [ ],\n                                        \"gender\" : [ ]\n                                },\n                                \"isUnique\" : false,\n                                \"isSparse\" : false,\n                                \"isPartial\" : false,\n                                \"indexVersion\" : 2,\n                                \"direction\" : \"forward\",\n                                \"indexBounds\" : {\n                                        \"dob.age\" : [\n                                                \"[35.0, 35.0]\"\n                                        ],\n                                        \"gender\" : [\n                                                \"[\\\"male\\\", \\\"male\\\"]\"\n                                        ]\n                                },\n                                \"keysExamined\" : 43,\n                                \"seeks\" : 1,\n                                \"dupsTested\" : 0,\n                                \"dupsDropped\" : 0\n                        }\n                }\n        },\n        \"command\" : {\n                \"find\" : \"infos\",\n                \"filter\" : {\n                        \"dob.age\" : 35,\n                        \"gender\" : \"male\"\n                },\n                \"$db\" : \"persons\"\n        },\n}\n</code></pre> <p>If we just look for the age, then also mongodb will use this index as \"dob.age\" comes first in the index order.</p> <pre><code>&gt; db.infos.explain(\"executionStats\").find({\"dob.age\" : 35})\n{\n        \"explainVersion\" : \"1\",\n        \"queryPlanner\" : {\n                \"namespace\" : \"persons.infos\",\n                \"indexFilterSet\" : false,\n                \"parsedQuery\" : {\n                        \"dob.age\" : {\n                                \"$eq\" : 35\n                        }\n                },\n                \"maxIndexedOrSolutionsReached\" : false,\n                \"maxIndexedAndSolutionsReached\" : false,\n                \"maxScansToExplodeReached\" : false,\n                \"winningPlan\" : {\n                        \"stage\" : \"FETCH\",\n                        \"inputStage\" : {\n                                \"stage\" : \"IXSCAN\",\n                                \"keyPattern\" : {\n                                        \"dob.age\" : 1,\n                                        \"gender\" : 1\n                                },\n                                \"indexName\" : \"dob.age_1_gender_1\",\n                                \"isMultiKey\" : false,\n                                \"multiKeyPaths\" : {\n                                        \"dob.age\" : [ ],\n                                        \"gender\" : [ ]\n                                },\n                                \"isUnique\" : false,\n                                \"isSparse\" : false,\n                                \"isPartial\" : false,\n                                \"indexVersion\" : 2,\n                                \"direction\" : \"forward\",\n                                \"indexBounds\" : {\n                                        \"dob.age\" : [\n                                                \"[35.0, 35.0]\"\n                                        ],\n                                        \"gender\" : [\n                                                \"[MinKey, MaxKey]\"\n                                        ]\n                                }\n                        }\n                },\n                \"rejectedPlans\" : [ ]\n        },\n        \"executionStats\" : {\n                \"executionSuccess\" : true,\n                \"nReturned\" : 95,\n                \"executionTimeMillis\" : 0,\n                \"totalKeysExamined\" : 95,\n                \"totalDocsExamined\" : 95,\n                \"executionStages\" : {\n                        \"stage\" : \"FETCH\",\n                        \"nReturned\" : 95,\n                        \"executionTimeMillisEstimate\" : 0,\n                        \"works\" : 96,\n                        \"advanced\" : 95,\n                        \"needTime\" : 0,\n                        \"needYield\" : 0,\n                        \"saveState\" : 0,\n                        \"restoreState\" : 0,\n                        \"isEOF\" : 1,\n                        \"docsExamined\" : 95,\n                        \"alreadyHasObj\" : 0,\n                        \"inputStage\" : {\n                                \"stage\" : \"IXSCAN\",\n                                \"nReturned\" : 95,\n                                \"executionTimeMillisEstimate\" : 0,\n                                \"works\" : 96,\n                                \"advanced\" : 95,\n                                \"needTime\" : 0,\n                                \"needYield\" : 0,\n                                \"saveState\" : 0,\n                                \"restoreState\" : 0,\n                                \"isEOF\" : 1,\n                                \"keyPattern\" : {\n                                        \"dob.age\" : 1,\n                                        \"gender\" : 1\n                                },\n                                \"indexName\" : \"dob.age_1_gender_1\",\n                                \"isMultiKey\" : false,\n                                \"multiKeyPaths\" : {\n                                        \"dob.age\" : [ ],\n                                        \"gender\" : [ ]\n                                },\n                                \"isUnique\" : false,\n                                \"isSparse\" : false,\n                                \"isPartial\" : false,\n                                \"indexVersion\" : 2,\n                                \"direction\" : \"forward\",\n                                \"indexBounds\" : {\n                                        \"dob.age\" : [\n                                                \"[35.0, 35.0]\"\n                                        ],\n                                        \"gender\" : [\n                                                \"[MinKey, MaxKey]\"\n                                        ]\n                                },\n                                \"keysExamined\" : 95,\n                                \"seeks\" : 1,\n                                \"dupsTested\" : 0,\n                                \"dupsDropped\" : 0\n                        }\n                }\n        },\n        \"command\" : {\n                \"find\" : \"infos\",\n                \"filter\" : {\n                        \"dob.age\" : 35\n                },\n                \"$db\" : \"persons\"\n        }\n}\n</code></pre> <p>But if we only search will the gender then index has no use because gender is not sorted primarily. It is secondary sort on the dob.age. Here mongodb will use the full COLLSCAN. </p><pre><code>&gt; db.infos.explain(\"executionStats\").find({\"gender\" : \"male\"})\n{\n        \"explainVersion\" : \"1\",\n        \"queryPlanner\" : {\n                \"namespace\" : \"persons.infos\",\n                \"indexFilterSet\" : false,\n                \"parsedQuery\" : {\n                        \"gender\" : {\n                                \"$eq\" : \"male\"\n                        }\n                },\n                \"maxIndexedOrSolutionsReached\" : false,\n                \"maxIndexedAndSolutionsReached\" : false,\n                \"maxScansToExplodeReached\" : false,\n                \"winningPlan\" : {\n                        \"stage\" : \"COLLSCAN\",\n                        \"filter\" : {\n                                \"gender\" : {\n                                        \"$eq\" : \"male\"\n                                }\n                        },\n                        \"direction\" : \"forward\"\n                },\n                \"rejectedPlans\" : [ ]\n        },\n        \"executionStats\" : {\n                \"executionSuccess\" : true,\n                \"nReturned\" : 2435,\n                \"executionTimeMillis\" : 4,\n                \"totalKeysExamined\" : 0,\n                \"totalDocsExamined\" : 5000,\n                \"executionStages\" : {\n                        \"stage\" : \"COLLSCAN\",\n                        \"filter\" : {\n                                \"gender\" : {\n                                        \"$eq\" : \"male\"\n                                }\n                        },\n                        \"nReturned\" : 2435,\n                        \"executionTimeMillisEstimate\" : 0,\n                        \"works\" : 5002,\n                        \"advanced\" : 2435,\n                        \"needTime\" : 2566,\n                        \"needYield\" : 0,\n                        \"saveState\" : 5,\n                        \"restoreState\" : 5,\n                        \"isEOF\" : 1,\n                        \"direction\" : \"forward\",\n                        \"docsExamined\" : 5000\n                }\n        },\n        \"command\" : {\n                \"find\" : \"infos\",\n                \"filter\" : {\n                        \"gender\" : \"male\"\n                },\n                \"$db\" : \"persons\"\n        }\n}\n</code></pre> <p>Sorting with indexing:</p> <p>If we are sorting on any field and that field has an indexing, then mongodb will not sort it will directly use the indexed records as mongodb already has a sorted list on that field.</p> <p>If we are trying to sort on a large number of documents, then it will time out. MongoDB has a memory of <code>32 megabytes</code> of memory of sorting. By default, mongodb loads all the documents on its memory then it sorts on them. So, without indexing sometimes it is not possible to get the sorted documents.</p> <p>When we are creating any index on that time, we can specify that the index will be <code>unique</code> or not. By default, the indexing on <code>$id</code> holds unique criteria. </p><pre><code>&gt; db.infos.createIndex({ email : 1 }, { unique : true })\n</code></pre> <p>Before creating index if there is already any duplicate email available then it will throw an error. </p><pre><code>&gt; db.infos.createIndex({ email : 1 }, { unique : true })\n{\n        \"ok\" : 0,\n        \"errmsg\" : \"Index build failed: 8aff9b57-7fce-4ff9-8631-4f22c63ddaff: Collection persons.infos ( c6d8709f-2a51-4bda-ac9e-343a639304d6 ) :: caused by :: E11000 duplicate key error collection: persons.infos index: email_1 dup key: { email: \\\"abigail.clark@example.com\\\" }\",\n        \"code\" : 11000,\n        \"codeName\" : \"DuplicateKey\",\n        \"keyPattern\" : {\n                \"email\" : 1\n        },\n        \"keyValue\" : {\n                \"email\" : \"abigail.clark@example.com\"\n        }\n}\n</code></pre>"},{"location":"mongodb/#partial-filterindexing","title":"Partial filter/Indexing","text":"<p>We can always use compound indexing but the problem with the compound indexing is that it takes much space in discs. So, in that case we can use partial filter like if we know that gender male is frequently queried rather than female. So, we can create a partial index with gender male.</p> <p>Creating a partial index on gender <code>male</code> </p><pre><code>&gt; db.infos.createIndex({\"dob.age\" : 1}, {partialFilterExpression : {\"gender\" : 1}} )\n{\n        \"numIndexesBefore\" : 1,\n        \"numIndexesAfter\" : 2,\n        \"createdCollectionAutomatically\" : false,\n        \"ok\" : 1\n}\n</code></pre> <p>Getting all the index information </p><pre><code>&gt; db.infos.getIndexes()\n[\n    {\n        \"v\" : 2,\n        \"key\" : {\n            \"_id\" : 1\n        },\n        \"name\" : \"_id_\"\n    },\n    {\n        \"v\" : 2,\n        \"key\" : {\n            \"dob.age\" : 1\n        },\n        \"name\" : \"dob.age_1\",\n        \"partialFilterExpression\" : {\n            \"gender\" : 1\n        }\n    }\n]\n</code></pre> <p>Drawback of this partial filter is that now when we just query for the <code>\"dob.age\"</code> it will not use <code>IXSCAN</code> it will use the <code>COLLSCAN</code>. But if we also mention gender male then it will use the <code>IXSCAN</code>.</p> <p>Advantage of partial filter is that now the write query is more efficient as the size of the ordered list is small.</p> <p>If we have an index on <code>email</code> and <code>unique true</code> and if we enter document <code>without email</code> then mongodb will treat that document as email equal to <code>null</code>. Again, if we try to <code>insert</code> any document <code>without</code> email then mongoDB will <code>throw an exception</code> as email <code>null</code> is already stored in ordered list. We cannot add null value again.</p> <p>To allow this condition we can use unique true with partial filter expression. </p><pre><code>&gt; db.infos.createIndex({\"dob.age\" : 1}, {unique : true, partialFilterExpression : {\"email\" : {exists : true}}} )\n{\n        \"numIndexesBefore\" : 1,\n        \"numIndexesAfter\" : 2,\n        \"createdCollectionAutomatically\" : false,\n        \"ok\" : 1\n}\n</code></pre>"},{"location":"mongodb/#time-to-live-indexttl","title":"Time to live index(TTL)","text":"<p>It is only applicable for <code>date or timestamp</code>. With this indexing after certain time the document will automatically be <code>deleted</code>.</p> <p>If there is already some document and then we are adding this <code>index</code>, then at the time of index creation it will not check the existing documents. When we insert any new data then it will evaluate all the documents again and then it will use <code>TTL</code> index.</p> <pre><code>&gt; db.sessions.createIndex({ createdAt : 1} , {expireAfterSeconds : 10})\n\n&gt; db.sessions.insertOne({data : \"I am Abhishek\", createdAt : new Date()})\n{\n    \"acknowledged\" : true,\n    \"insertedId\" : ObjectId(\"62da72b385a6e4bfe5a374cb\")\n}\n\n&gt; db.sessions.findOne()\n{\n    \"_id\" : ObjectId(\"62da72b385a6e4bfe5a374cb\"),\n    \"data\" : \"I am Abhishek\",\n    \"createdAt\" : ISODate(\"2022-07-22T09:49:39.459Z\")\n}\n\n&gt; db.sessions.createIndex({ createdAt : 1} , {expireAfterSeconds : 10})\n{\n    \"numIndexesBefore\" : 1,\n    \"numIndexesAfter\" : 2,\n    \"createdCollectionAutomatically\" : false,\n    \"ok\" : 1\n}\n</code></pre> <p>Now with this index the documents will be delete after <code>10</code> seconds. This can be useful for session or carts in online shopping where the cart item automatically deletes after one day.</p>"},{"location":"mongodb/#query-diagnosis-and-query-planning","title":"Query Diagnosis and &amp; Query Planning","text":"<p>explain() method takes three type of string:</p> <ul> <li>\"queryPlanner\": Show summary for executed query and winning plan</li> <li>\"executionStats\": Show detailed summary for executed query and winning plan and rejected plans.</li> <li>\"allPlansExecution\": Show detailed summary for executed query and winning plan and winning plan decision process.</li> </ul> <p>For determining the query is efficient or not we must check following things:</p> <p>Processing time in milliseconds, no of keys examined (if index scan happened), No of documents examined, no of documents returned.</p> <p>The keys and documents examined should be close together and documents examined and returned should be closed or documents should be zero so that it looked at zero documents.  In a so-called covered query, it will be happening.</p> <p>Covered query:</p> <p>If we have an indexing on name and we are only querying for name on that time mongodb will not even look to the documents, instead it will directly return the name from the indexed ordered list.</p> <p>Example of this type of query is like: </p><pre><code>db.infos.findOne({ \"name\" : \"Abhishek\"}, { _id: 0, name : 1})\n</code></pre> <p>Suppose we have an index on <code>name</code> and another index one <code>age and name</code> (the ordering is important here). Now if we search for any document with <code>name and age</code> then mongodb will use the <code>compound index</code>, it will use the single index on <code>name</code>. If we do an <code>explain(\"executionStats\")</code> then <code>age_1_name_1</code> will fall under <code>winning plan</code> and <code>name_1</code> will fall under rejected plans.</p> <p>To find the <code>winning plan</code> mongodb check the query and available index then it will choose among them. So every time there is a query mongodb tries to find a <code>winning plan</code>, but again it will be having the extra step to find among all the plans. So mongodb save the winning plan in the caches for the query. This cache is not for forever. Mongodb resets the cache after db restarts, after few inserts or there is any rebuilt of index or changes in index.</p>"},{"location":"mongodb/#multikey-index","title":"Multikey index","text":"<p>We can also create indexes on array values. Let's say we are adding one document like this. </p><pre><code>&gt; db.infos.insertOne({\"name\" : \"Abhishek\", \"gender\" : \"male\", \"hobbies\" : [\"Sports\", \"Coding\"]})\n{\n        \"acknowledged\" : true,\n        \"insertedId\" : ObjectId(\"62dcaf7185a6e4bfe5a374cc\")\n}\n&gt; db.infos.createIndex({hobbies: 1})\n{\n        \"numIndexesBefore\" : 1,\n        \"numIndexesAfter\" : 2,\n        \"createdCollectionAutomatically\" : false,\n        \"ok\" : 1\n}\n&gt; db.infos.explain().find({hobbies : \"Coding\"})\n{\n    \"explainVersion\" : \"1\",\n    \"queryPlanner\" : {\n        \"namespace\" : \"persons.infos\",\n        \"indexFilterSet\" : false,\n        \"parsedQuery\" : {\n            \"hobbies\" : {\n                \"$eq\" : \"Coding\"\n            }\n        },\n        \"queryHash\" : \"895C9692\",\n        \"planCacheKey\" : \"439794C9\",\n        \"maxIndexedOrSolutionsReached\" : false,\n        \"maxIndexedAndSolutionsReached\" : false,\n        \"maxScansToExplodeReached\" : false,\n        \"winningPlan\" : {\n            \"stage\" : \"FETCH\",\n            \"inputStage\" : {\n                \"stage\" : \"IXSCAN\",\n                \"keyPattern\" : {\n                    \"hobbies\" : 1\n                },\n                \"indexName\" : \"hobbies_1\",\n                \"isMultiKey\" : true,\n                \"multiKeyPaths\" : {\n                    \"hobbies\" : [\n                        \"hobbies\"\n                    ]\n                },\n                \"isUnique\" : false,\n                \"isSparse\" : false,\n                \"isPartial\" : false,\n                \"indexVersion\" : 2,\n                \"direction\" : \"forward\",\n                \"indexBounds\" : {\n                    \"hobbies\" : [\n                        \"[\\\"Coding\\\", \\\"Coding\\\"]\"\n                    ]\n                }\n            }\n        },\n        \"rejectedPlans\" : [ ]\n    },\n    \"command\" : {\n        \"find\" : \"infos\",\n        \"filter\" : {\n            \"hobbies\" : \"Coding\"\n        },\n        \"$db\" : \"persons\"\n    },\n}\n</code></pre> <p>Here <code>multikey</code> is true.</p> <p>When we are creating index on array values. On that time there will be a ordered list with all the elements with array. It polls out all the elements of the array and stores as a separate element. So, it is larger than the size of the document.</p> <p>If the array consists of documents, then we have to query with that document otherwise it will not use <code>IXSCAN</code>. Suppose we have address array with <code>homeAddress</code> and we are creating index on arrays. </p><pre><code>{ \"address\": [\n    { \"homeAddress\" : \"18 No alep khan mahalla road\" }, \n    { \"homeAddress\" : \"Rameswara waterview block 1,4B\" }\n]}\n</code></pre> <p>Here we have to search like this: </p><pre><code>db.infos.find({\n    \"address\": { \"homeAddress\" : \"18 No alep khan mahalla road\" }\n})\n</code></pre> Otherwise indexing will not work. We can also use on <code>\"address.homeAddress\"</code>.  We can create compound indexes with multikey index like with name and address array.  It will do a <code>cartesian product</code> of the name and address values. Then it will store in the ordered list.  But we cannot create a compound index if both values are array."},{"location":"mongodb/#text-index","title":"Text index","text":"<p>If we search using regex that is very low in performance rather, we can use text indexes. Text string is just an array of words. So, mongodb stores the main keywords and removes the stop words like \"is\", \"the\", \"a\" etc. The main thing with text index it we can only create on index, which is type of text, because it is expensive to store all the keywords. If we have any criteria to use on both rather, we can create compound index of type text with the two fields. </p><pre><code>db.infos.createIndex({ \"description\" : \"text\" })\n</code></pre> We can not specify 1 or -1 while creating the index. <p>We can search like this. We cannot use regular queries. Text index is expensive, and we have to use it like this. </p><pre><code>db.infos.find({ \"$text\" : { \"$search\" : \"pretty\" }})\n</code></pre> <p>If we search for \"red book\" then the query <code>db.infos.find({ \"$text\" : { \"$search\" : \"red book\" }})</code> will not work as it will split the query string into multiple word, then it will search individually like it will search for red and it will search for book then it will combine the result. So, we have to use quotation mark around our query if we are searching for phrases. </p><pre><code>db.infos.find({ \"$text\" : { \"$search\" : \"\\\"red book\\\"\" }})\n</code></pre> <p>If we have more than one result, then behind the scenes mongodb assigns meta score to the documents. Higher the score means that the document matches with our query better. To see the score with have to project the score as well. </p><pre><code>db.infos.find(\n    { $text : { $search : \"awesome book\" }}, \n    { score : { $meta : \"textScore\" }}\n)\n</code></pre> <p>we can also show the results with sorted based on scores. </p><pre><code>db.infos.find(\n    { $text : { $search : \"awesome book\" }} , \n    { score : { $meta : \"textScore\" }}\n).sort({ \n    score : { $meta : \"textScore\" }\n})\n</code></pre> <p>It will be a <code>decreasing</code> type of sorting.  We can use more than field for text index. To drop an index of text, we must drop by name. </p><pre><code>db.infos.createIndex({ \n    title : \"text\" , \n    description : text \n})\n</code></pre> <p>it will create an index using the keywords of both fields. We can search like previous. Case does not matter for text index. </p><pre><code>db.infos.find({ \n    \"$text\" : { \"$search\" : \"pretty\" }\n})\n</code></pre> <p>We can also rule out for the specific words. </p><pre><code>db.infos.find({ \n    \"$text\" : { \"$search\" : \"pretty -books\" }\n})\n</code></pre> we have to add minus <code>(-)</code> before that word. It will for <code>pretty word</code> where book word is not present. <p>We can also use language in text index as stop words for different language is different. Default language is English though.  There is list of supported language that we can use. Default language is very important when it comes to text index. </p> <pre><code>db.infos.createIndex(\n    { title : \"text\" }, \n    { default_laguage : \"germany\"}\n)\n</code></pre> <p>We can also assign weight to the fields which will be used to create text index. </p><pre><code>db.infos.createIndex(\n    { title : \"text\" , summary : \"text\" }, \n    { weights : { title : 5 , summary : 1 }\n)\n</code></pre> <p>We also search in case sensitive way like the following. </p><pre><code>db.infos.find({ \n    \"$text\" : { \"$search\" : \"pretty\" }, \n    $caseSentitive : true \n})\n</code></pre>"},{"location":"mongodb/#building-index","title":"Building Index","text":"<p>When we are creating any index using createIndex method on that time the collection got locked. On that time if we try to insert any document then we have to wait for a certain time. The down time will depend on the size of the collection. It is adjustable in lower environment, but we cannot afford this in production. To deal with this create index in background. The time taken for creating the index is slow in background than foreground. </p><pre><code>db.infos.createIndex(\n    { \"age\" : 1 } , \n    { \"background\" : true }\n)\n</code></pre>"},{"location":"mongodb/#more-examples","title":"More Examples","text":""},{"location":"mongodb/#list-indexes","title":"List Indexes","text":"<p>To list all indexes on a collection: </p><pre><code>db.coll.getIndexes()\n</code></pre> <pre><code>db.coll.getIndexKeys()\n</code></pre>"},{"location":"mongodb/#create-indexes","title":"Create Indexes","text":"<p>To create different types of indexes:</p> <p>single field index </p><pre><code>db.coll.createIndex({\"name\": 1})\n</code></pre> <p>compound index </p><pre><code>db.coll.createIndex({\"name\": 1, \"date\": 1})\n</code></pre> <p>text index </p><pre><code>db.coll.createIndex({foo: \"text\", bar: \"text\"}) // \n</code></pre> <p>wildcard text index </p><pre><code>db.coll.createIndex({\"$**\": \"text\"})\n</code></pre> <p>wildcard index </p><pre><code>db.coll.createIndex({\"userMetadata.$**\": 1})\n</code></pre> <p>2d index </p><pre><code>db.coll.createIndex({\"loc\": \"2d\"})\n</code></pre> <p>2dsphere index </p><pre><code>db.coll.createIndex({\"loc\": \"2dsphere\"})\n</code></pre> <p>hashed index </p><pre><code>db.coll.createIndex({\"_id\": \"hashed\"})\n</code></pre> <p>Index Options</p> <p>TTL index </p><pre><code>db.coll.createIndex({\"lastModifiedDate\": 1}, {expireAfterSeconds: 3600})\n</code></pre> <p>Unique index </p><pre><code>db.coll.createIndex({\"name\": 1}, {unique: true})\n</code></pre> <p>partial index </p><pre><code>db.coll.createIndex({\"name\": 1}, {partialFilterExpression: {age: {$gt: 18}}})\n</code></pre> <p>case insensitive index with strength = 1 or 2 </p><pre><code>db.coll.createIndex({\"name\": 1}, {collation: {locale: 'en', strength: 1}})\n</code></pre> <p>Sparse index </p><pre><code>db.coll.createIndex({\"name\": 1 }, {sparse: true})\n</code></pre>"},{"location":"mongodb/#drop-indexes","title":"Drop Indexes","text":"<p>To drop an index by name: </p><pre><code>db.coll.dropIndex(\"name_1\")\n</code></pre>"},{"location":"mongodb/#hideunhide-indexes","title":"Hide/Unhide Indexes","text":"<p>To hide or unhide an index: </p><pre><code>db.coll.hideIndex(\"name_1\")\n</code></pre> <pre><code>db.coll.unhideIndex(\"name_1\")\n</code></pre>"},{"location":"mongodb/advance-commands/","title":"advance commands","text":""},{"location":"mongodb/advance-commands/#handy-commands","title":"Handy commands","text":"<p>Switch to admin database and create a user: </p><pre><code>use admin\ndb.createUser({\"user\": \"root\", \"pwd\": passwordPrompt(), \"roles\": [\"root\"]})\n</code></pre> <p>Drop a user: </p><pre><code>db.dropUser(\"root\")\n</code></pre> <p>Authenticate a user: </p><pre><code>db.auth(\"user\", passwordPrompt())\n</code></pre> <p>Switch to test database: </p><pre><code>use test\n</code></pre> <p>Get sibling database: </p><pre><code>db.getSiblingDB(\"dbname\")\n</code></pre> <p>Get current operations: </p><pre><code>db.currentOp()\n</code></pre> <p>Kill an operation: </p><pre><code>db.killOp(123) // opid\n</code></pre> <p>Lock and unlock the database: </p><pre><code>db.fsyncLock()\ndb.fsyncUnlock()\n</code></pre> <p>Get collection names and information: </p><pre><code>db.getCollectionNames()\ndb.getCollectionInfos()\ndb.printCollectionStats()\n</code></pre> <p>Get database statistics: </p><pre><code>db.stats()\n</code></pre> <p>Get replication information: </p><pre><code>db.getReplicationInfo()\ndb.printReplicationInfo()\n</code></pre> <p>Get server information: </p><pre><code>db.hello()\ndb.hostInfo()\n</code></pre> <p>Shutdown the server: </p><pre><code>db.shutdownServer()\n</code></pre> <p>Get server status: </p><pre><code>db.serverStatus()\n</code></pre> <p>Get and set profiling level: </p><pre><code>db.getProfilingStatus()\ndb.setProfilingLevel(1, 200) // 0 == OFF, 1 == ON with slowms, 2 == ON\n</code></pre> <p>Enable and disable free monitoring: </p><pre><code>db.enableFreeMonitoring()\ndb.disableFreeMonitoring()\ndb.getFreeMonitoringStatus()\n</code></pre> <p>Create a view: </p><pre><code>db.createView(\"viewName\", \"sourceColl\", [{$project:{department: 1}}])\n</code></pre>"},{"location":"mongodb/advance-commands/#change-streams","title":"Change Streams","text":"<p>Watch for changes in a collection: </p><pre><code>watchCursor = db.coll.watch([ { $match : {\"operationType\" : \"insert\" } } ])\nwhile (!watchCursor.isExhausted()){\n   if (watchCursor.hasNext()){\n      print(tojson(watchCursor.next()));\n   }\n}\n</code></pre>"},{"location":"mongodb/advance-commands/#replica-set","title":"Replica Set","text":"<p>Get replica set status: </p><pre><code>rs.status()\n</code></pre> <p>Initialize a replica set: </p><pre><code>rs.initiate({\n  \"_id\": \"RS1\",\n  members: [\n    { _id: 0, host: \"mongodb1.net:27017\" },\n    { _id: 1, host: \"mongodb2.net:27017\" },\n    { _id: 2, host: \"mongodb3.net:27017\" }\n  ]\n})\n</code></pre> <p>Add a member to the replica set: </p><pre><code>rs.add(\"mongodb4.net:27017\")\n</code></pre> <p>Add an arbiter to the replica set: </p><pre><code>rs.addArb(\"mongodb5.net:27017\")\n</code></pre> <p>Remove a member from the replica set: </p><pre><code>rs.remove(\"mongodb1.net:27017\")\n</code></pre> <p>Get replica set configuration: </p><pre><code>rs.conf()\n</code></pre> <p>Get replica set hello information: </p><pre><code>rs.hello()\n</code></pre> <p>Print replication information: </p><pre><code>rs.printReplicationInfo()\nrs.printSecondaryReplicationInfo()\n</code></pre> <p>Reconfigure the replica set: </p><pre><code>rs.reconfig(config)\nrs.reconfigForPSASet(memberIndex, config, { options })\n</code></pre> <p>Set read preference: </p><pre><code>db.getMongo().setReadPref('secondaryPreferred')\n</code></pre> <p>Step down the primary: </p><pre><code>rs.stepDown(20, 5) // (stepDownSecs, secondaryCatchUpPeriodSecs)\n</code></pre>"},{"location":"mongodb/advance-commands/#sharded-cluster","title":"Sharded Cluster","text":"<p>Print sharding status: </p><pre><code>db.printShardingStatus()\n</code></pre> <p>Get sharding status: </p><pre><code>sh.status()\n</code></pre> <p>Add a shard to the cluster: </p><pre><code>sh.addShard(\"rs1/mongodb1.example.net:27017\")\n</code></pre> <p>Shard a collection: </p><pre><code>sh.shardCollection(\"mydb.coll\", {zipcode: 1})\n</code></pre> <p>Move a chunk to a different shard: </p><pre><code>sh.moveChunk(\"mydb.coll\", { zipcode: \"53187\" }, \"shard0019\")\n</code></pre> <p>Split a chunk at a specific point: </p><pre><code>sh.splitAt(\"mydb.coll\", {x: 70})\n</code></pre> <p>Split a chunk based on a query: </p><pre><code>sh.splitFind(\"mydb.coll\", {x: 70})\n</code></pre> <p>Start and stop the balancer: </p><pre><code>sh.startBalancer()\nsh.stopBalancer()\n</code></pre> <p>Enable and disable balancing for a collection: </p><pre><code>sh.disableBalancing(\"mydb.coll\")\nsh.enableBalancing(\"mydb.coll\")\n</code></pre> <p>Get and set balancer state: </p><pre><code>sh.getBalancerState()\nsh.setBalancerState(true/false)\n</code></pre> <p>Check if the balancer is running: </p><pre><code>sh.isBalancerRunning()\n</code></pre> <p>Start and stop auto-merger: </p><pre><code>sh.startAutoMerger()\nsh.stopAutoMerger()\n</code></pre> <p>Enable and disable auto-merger: </p><pre><code>sh.enableAutoMerger()\nsh.disableAutoMerger()\n</code></pre> <p>Update zone key range: </p><pre><code>sh.updateZoneKeyRange(\"mydb.coll\", {state: \"NY\", zip: MinKey }, { state: \"NY\", zip: MaxKey }, \"NY\")\n</code></pre> <p>Remove range from zone: </p><pre><code>sh.removeRangeFromZone(\"mydb.coll\", {state: \"NY\", zip: MinKey }, { state: \"NY\", zip: MaxKey })\n</code></pre> <p>Add and remove shard from zone: </p><pre><code>sh.addShardToZone(\"shard0000\", \"NYC\")\nsh.removeShardFromZone(\"shard0000\", \"NYC\")\n</code></pre>"},{"location":"mongodb/aggregation-framework/","title":"aggregation framework","text":""},{"location":"mongodb/aggregation-framework/#introduction","title":"Introduction","text":"<p>Aggregation framework is just another find method we could say but it has some other advantages too. In aggregation framework we basically create pipeline of steps which operates on datas of that collection.</p> <p>Aggregation Pipeline </p><pre><code>db.listingsAndReviews.aggregate([\n    {\n        $match: {\n            number_of_reviews: { $gte: 100 } // Listings with more than 100 reviews\n        } \n    },\n    {\n        $group : {\n            _id : \"$property_type\",        // Group by property type\n            count: { $sum : 1 },           // Total listings\n            reviewCount: { $sum : \"$number_of_reviews\" },        // Total reviews\n            avgPrice: { $avg : \"$price\" }, // Average price\n        },\n    },\n    {\n        $project: {\n            _id: 1,\n            count: 1,\n            reviewCount: 1,\n            avgPrice: { $ceil : \"$avgPrice\" } // Round up avgPrice\n        }\n    },\n    {\n        $match: {\n            reviewCount: { $gte: 10000 } // Listings by property with more than 10000 total reviews\n        } \n    },\n    {\n        $sort : { \n            count : -1, // Sort by count descending\n            avgPrice: 1 // Sort by avgPrice ascending\n        }\n    }\n])\n</code></pre> <p><code>$lookup (Join)</code> </p><pre><code>db.accounts.aggregate([\n   {\n      $lookup:\n        {\n          from: \"transactions\",         // join with 'transactions' collection\n          localField: \"account_id\",     // field from the 'accounts' collection\n          foreignField: \"account_id\",   // field from the 'transactions' collection\n          as: \"customer_orders\"         // output array field\n        }\n   },\n   {\n      $match: { $expr: { $lt: [ {$size: \"$customer_orders\"}, 5 ] } } // filter for documents where 'customer_orders' is &lt; 5\n   },\n])\n</code></pre>"},{"location":"mongodb/create/","title":"create","text":""},{"location":"mongodb/create/#general","title":"General","text":"<p>We have three methods for inserting documents</p> <ul> <li><code>insertOne</code> </li> <li><code>insertMany</code></li> <li><code>insert</code></li> </ul> <p>Though <code>insert</code> method is flexible enough to handle one document or multiple but still it is deprecated on purpose.</p> <p>Also, we can directly import from a json file using mongoimort command</p> <p>If we are using insert many and we are inserting multiple documents in a shot then if there is a issue with any document in that list then from that onwards there will be no insertions, only the documents before the wrecked document will be inserted, it will not be rolled back.</p> <p>Like for the following code there is a issue in third document </p><pre><code>&gt; db.hobbies.insertMany([{_id: \"yoga\"}, {_id: \"sports\"} ,{_id: \"yoga\"}, {_id: \"maths\"}])\n\"errmsg\" : \"E11000 duplicate key error collection: contacts.hobbies index: _id_ dup key: { _id: \\\"yoga\\\" }\",\n\n&gt; db.hobbies.find().toArray()\n[ { \"_id\" : \"yoga\" }, { \"_id\" : \"sports\" } ]\n</code></pre> <p>But to remove this one we can pass one argument {ordered: false}. By default, it is true. It defines that the insertion will be ordered or not.</p> <p>If we again try to run the previous code in shell it will again give us the error, but it will not stop to the error document rather it will insert all the correct documents. </p><pre><code>&gt; db.hobbies.insertMany([{_id: \"yoga\"}, {_id: \"sports\"}, {_id: \"yoga\"}, {_id: \"maths\"}], {ordered: false})\n\"E11000 duplicate key error collection: contacts.hobbies index: _id_ dup key: { _id: \\\"yoga\\\" }\", \"E11000 duplicate key error collection: contacts.hobbies index: _id_ dup key: { _id: \\\"sports\\\" }\",\n\n&gt; db.hobbies.find().toArray()\n[ { \"_id\" : \"yoga\" }, { \"_id\" : \"sports\" }, { \"_id\" : \"maths\" } ]\n</code></pre> <p>Example of <code>insertOne</code> and <code>insertMany</code> </p><pre><code>&gt; use contacts\nswitched to db contacts\n\n&gt; db.persons.insertOne({name:\"Abhishek Ghosh\"})\n{\n        \"acknowledged\" : true,\n        \"insertedId\" : ObjectId(\"62aadb4256184ff0056adbd7\")\n}\n\n&gt; db.persons.insertMany([{name:\"Abhishek Pal\"},{name:\"Bishal Mukherjee\"}])\n{\n        \"acknowledged\" : true,\n        \"insertedIds\" : [\n                ObjectId(\"62aadbed56184ff0056adbd8\"),\n                ObjectId(\"62aadbed56184ff0056adbd9\")\n        ]\n}\n</code></pre>"},{"location":"mongodb/create/#writeconcern","title":"WriteConcern","text":""},{"location":"mongodb/create/#description","title":"Description","text":"<p>Write concern describes the level of acknowledgment requested from MongoDB for write operations to a standalone mongod or to replica sets or to sharded clusters. In sharded clusters, mongos instances will pass the write concern on to the shards.</p> <p>the write concern is a specification of MongoDB for write operations that determines the acknowledgement you want after a write operation has taken place. MongoDB has a default write concern of always acknowledging all writes, which means that after every write, MongoDB must always return an acknowledgement (in a form of a document), meaning that it was successful. When asking for write acknowledgement, if none isn't returned (in case of failover, crashes), the write isn't successful. This behavior is very useful specially on replica set usage, since you will have more than one mongod instance, and depending on your needs, maybe you don't want all instances to acknowledge the write, just a few, to speed up writes. Also, when to specify a write concern, you can specify journal writing, so you can guarantee that operation result and any rollbacks required if a failover happens. More information, here.</p> <p>In your case, it depends on how many mongod (if you have replica sets or just a single server) instances you have. Since \"always acknowledge\" is the default, you may want to change it if you have to manage replica sets operations and speed things up or just doesn't care about write acknowledgement in a single instance (which is not so good, since it's a single server only).</p> <p>Write concern can include the following fields: <code>{w: &lt;value&gt;, j: &lt;boolean&gt;, wtimeout: &lt;number&gt;}</code> </p><pre><code>{w: 1, j: true, wtimeout: 500}\n</code></pre> <p>the <code>w</code> option to request acknowledgment that the write operation has propagated to a specified number of mongod instances or to mongod instances with specified tags.</p> <p>the <code>j</code> option to request acknowledgment that the write operation has been written to the on-disk journal.</p> <p>the <code>wtimeout</code> option to specify a time limit to prevent write operations from blocking indefinitely.</p>"},{"location":"mongodb/create/#write-concern-levels","title":"Write Concern Levels","text":"<p>MongoDB has the following levels of conceptual write concern, listed from weakest to strongest:</p>"},{"location":"mongodb/create/#unacknowledged","title":"Unacknowledged","text":"<p>With an <code>unacknowledged</code> write concern, MongoDB does not acknowledge the receipt of write operations. <code>unacknowledged</code> is like errors ignored; however, drivers will attempt to receive and handle network errors when possible. The driver's ability to detect network errors depends on the system's networking configuration. Write operation to a <code>mongod</code> instance with write concern of <code>unacknowledged</code>. The client does not wait for any acknowledgment. </p>"},{"location":"mongodb/create/#acknowledged","title":"Acknowledged","text":"<p>With a receipt acknowledged write concern, the mongod confirms the receipt of the write operation. Acknowledged write concern allows clients to catch network, duplicate key, and other errors. This is default write concern. Write operation to a <code>mongod</code> instance with write concern of <code>acknowledged</code>. The client waits for acknowledgment of success or exception.</p>"},{"location":"mongodb/create/#journaled","title":"Journaled","text":"<p>With a journaled write concern, the MongoDB acknowledges the write operation only after committing the data to the journal. This write concern ensures that MongoDB can recover the data following a shutdown or power interruption. You must have journaling enabled to use this write concern. Write operation to a <code>mongod</code> instance with write concern of <code>journaled</code>. The <code>mongod</code> sends acknowledgment after it commits the write operation to the journal.</p>"},{"location":"mongodb/create/#replica-acknowledged","title":"Replica Acknowledged","text":"<p>Replica sets present additional considerations with regards to write concern. The default write concern only requires acknowledgement from the primary. With <code>replica acknowledged</code> write concern, you can guarantee that the write operation propagates to additional members of the replica set. Write operation to a replica set with write concern level of <code>w:2</code> or write to the primary and at least one secondary.</p>"},{"location":"mongodb/create/#reference","title":"Reference","text":"<ul> <li>Write Concern</li> <li>Journaling</li> </ul> <p>When we have millions of records inserting in seconds then on that time, we can skip the acknowledgement and use <code>w: 0</code>. By default is <code>undefined</code>.</p> <p>If <code>j: true</code>, then inserting will take some extra time as it will write on journal. By default, is <code>undefined</code>. Here it has the higher security.</p>"},{"location":"mongodb/create/#atomicity","title":"Atomicity","text":"<p>It means when we are inserting any document then either it will be saved as a whole, or it will not be saved at all if there is any issue. MongoDB provides atomic transaction guarantee.</p>"},{"location":"mongodb/create/#import-from-file","title":"Import from file","text":"<p>Lastly, we can import json file in and save it mongodb.</p> <p>if it is a single document </p><pre><code>mongoimport --db dbName --collection collectionName --file /path/fileName.json\n</code></pre> <p>if it is a array of documents. </p><pre><code>mongoimport --db dbName --collection collectionName --file /path/fileName.json --jsonArray\n</code></pre> <p>if we add <code>--drop</code> then it will delete previous data  </p>"},{"location":"mongodb/create/#more-examples","title":"More examples","text":"<p>Insert one document: </p><pre><code>db.coll.insertOne({name: \"Max\"})\n</code></pre> <p>Insert many documents (ordered bulk insert): </p><pre><code>db.coll.insertMany([{name: \"Max\"}, {name:\"Alex\"}])\n</code></pre> <p>Insert many documents (unordered bulk insert): </p><pre><code>db.coll.insertMany([{name: \"Max\"}, {name:\"Alex\"}], {ordered: false})\n</code></pre> <p>Insert a document with the current date: </p><pre><code>db.coll.insertOne({date: ISODate()})\n</code></pre> <p>Insert a document with write concern: </p><pre><code>db.coll.insertOne({name: \"Max\"}, {\"writeConcern\": {\"w\": \"majority\", \"wtimeout\": 5000}})\n</code></pre>"},{"location":"mongodb/crud/","title":"crud","text":""},{"location":"mongodb/crud/#create","title":"Create","text":"<ul> <li><code>insertOne(data, options)</code> -&gt; for inserting one item</li> <li><code>insertMany(data, options)</code> -&gt; for inserting multiple items</li> </ul>"},{"location":"mongodb/crud/#read","title":"Read","text":"<ul> <li><code>find(filter, options)</code> -&gt; find all the data based on the filter</li> <li><code>findOne(filter, options)</code> -&gt; find the first matching element based on the filter</li> </ul>"},{"location":"mongodb/crud/#update","title":"Update","text":"<ul> <li><code>updateOne(filter, data, options)</code> -&gt; to update one document</li> <li><code>updateMany(filter, data, options)</code> -&gt; for updating multiple documents</li> <li><code>replaceOne(filter, data, options)</code> -&gt; for replacing the entire document</li> </ul>"},{"location":"mongodb/crud/#delete","title":"Delete","text":"<ul> <li><code>deleteOne(filter, options)</code> -&gt; delete only the first item with matching filter</li> <li><code>deleteMany(filter, options)</code> -&gt; delete all items matching with the filter</li> </ul>"},{"location":"mongodb/crud/#examples","title":"Examples","text":"<p>Delete the first element with <code>name</code> as <code>\"Abhishek Ghosh\"</code>: </p><pre><code>db.products.deleteOne({name: \"Abhishek Ghosh\"})\n</code></pre> <p>Update the <code>age</code> to <code>24</code> where <code>name</code> is <code>\"Abhishek Pal\"</code>: </p><pre><code>db.products.updateOne({name: \"Abhishek Pal\"}, {$set: {age: 24}})\n</code></pre> <p>Add a field <code>height</code> to all the documents: </p><pre><code>db.products.updateMany({}, {$set: {height: \"Unknown\"}})\n</code></pre> <code>{}</code> this means all the documents. <p>Insert two items at a time: </p><pre><code>db.products.insertMany([\n    {name: \"Nasim Molla\", age: 25},\n    {name: \"Sayan Mandal\", age: 24}\n])\n</code></pre> <p>Find all the <code>students</code> whose <code>age</code> is <code>greater than 24</code>: </p><pre><code>db.products.find({age: {$gt: 24}})\n</code></pre> <p>Print all the <code>names</code> but not <code>_id</code> for the <code>student</code> whose <code>age</code> is <code>greater than 24</code>: </p><pre><code>db.products.find({age: {$gt: 24}}, {name: 1, _id: 0})\n</code></pre> <p>If we use update without <code>$set</code> then the document will be replaced with the data we have provided. (Rather use replace than update for full replacement): </p><pre><code>db.products.insertOne({})\n// {\"acknowledged\" : true,\"insertedId\" : ObjectId(\"62a7faec7866653913689afd\")}\n\ndb.products.update({_id: ObjectId(\"62a7faec7866653913689afd\")}, {name: \"Anirban Ghosh\", age: 23})\n// WriteResult({ \"nMatched\" : 1, \"nUpserted\" : 0, \"nModified\" : 1 })\n\ndb.products.find({_id: ObjectId(\"62a7faec7866653913689afd\")})\n// { \"_id\" : ObjectId(\"62a7faec7866653913689afd\"), \"name\" : \"Anirban Ghosh\", \"age\" : 23 }\n</code></pre> <p>Set status object for age greater than 24: </p><pre><code>db.products.updateMany(\n    {age: {$gt: 24}}, \n    {$set: {status: {married: false, single: false}}}\n)\n</code></pre> <p>If we have a list of strings like hobbies, we can search like this (It will find the first document that has a list of <code>hobbies</code> containing <code>\"Drama\"</code>): </p><pre><code>db.products.findOne({hobbies: \"Drama\"})\n</code></pre> <p>We can run a query in a nested object: </p><pre><code>db.products.findOne({\"status.single\": false})\n</code></pre> <p>To get rid of your data, you can simply load the database you want to get rid of (<code>use databaseName</code>) and then execute: </p><pre><code>db.dropDatabase()\n</code></pre> <p>Similarly, you could get rid of a single collection in a database via: </p><pre><code>db.&lt;collection-name&gt;.drop()\n</code></pre>"},{"location":"mongodb/crud/#what-is-cursor","title":"What is cursor?","text":"<ul> <li>When we find anything in the shell, rather than giving everything in one shot, it gives us the cursor of 20 elements, and to move to the next 20, we have to enter \"it\". To see it, we can use the <code>toArray</code> method on the cursor, which will exhaust the cursor and make one array with all the elements and show that.</li> <li>Cursor will fetch only the needed element.</li> <li><code>findOne</code> will not give us a cursor object as it will only give us one element.</li> <li><code>db.products.find().toArray()</code></li> <li>`db.products.find().forEach((doc) =&gt; {printjson(doc)})</li> </ul>"},{"location":"mongodb/crud/#what-is-projection","title":"What is projection?","text":"<ul> <li>Rather than showing all the fields of a document, we can choose whatever we want to show.</li> <li>It will also help us to reduce the bandwidth usage as the server will not send all the elements.</li> <li>To get all the student's <code>name</code> with <code>age</code> equals <code>24</code>:  <pre><code>db.products.find({age: 24}, {name: 1})\n</code></pre></li> <li>By default, <code>_id</code> is set to 1, so if we want to remove it as well, we have to use this type of query: <pre><code>db.products.find({age: 24}, {name: 1, _id: 0})\n</code></pre></li> <li>One Document can hold a maximum of 100 levels of nesting.</li> </ul>"},{"location":"mongodb/data-types/","title":"data types","text":""},{"location":"mongodb/data-types/#primitive-types","title":"Primitive types","text":"<ul> <li>Text -&gt; <code>\"Abhishek Ghosh\"</code></li> <li>Boolean -&gt; <code>true</code></li> <li>Number -&gt; <ul> <li><code>NimberInt()</code> -&gt; 1</li> <li><code>Integer(int32)</code> -&gt; 55</li> <li><code>NumberLong(int64)</code> -&gt; 1000000000</li> <li><code>NumberDecimal</code> -&gt; 12.0009</li> </ul> </li> <li>ObjectId -&gt; <code>ObjectId(\"62a6fddadb132197c5e8879f\")</code></li> <li>ISODate -&gt; <code>2022-06-14T05:45:29.379+00:00</code></li> <li>Timestamp </li> <li>Embedded Documents</li> <li>Arrays</li> </ul> <p><code>Db.stats()</code> will bring the statistic of the database.</p> <p>MongoDB has a couple of hard limits - most importantly, a single document in a collection (including all embedded documents it might have) must be less than equal to <code>16mb</code>. Additionally, you may only have <code>100 levels of embedded documents</code>.</p> <p>You can find all limits (in great detail) here: MongoDB Limits and Thresholds</p> <p>For the data types, MongoDB supports, you find a detailed overview on this page: BSON Types</p> <p>Important data type limits are:</p> <ul> <li>Normal integers (int32) can hold a maximum value of <code>-2,147,483,647 to +2,147,483,647</code></li> <li>Long integers (int64) can hold a maximum value of <code>-9,223,372,036,854,775,807 to +9,223,372,036,854,775,807</code></li> <li>Text can be as long as you want - the limit is the <code>16mb</code> restriction for the overall document</li> </ul> <p>It's also important to understand the difference between <code>int32 (NumberInt)</code>, <code>int64 (NumberLong)</code> and a normal number as you can enter it in the shell.</p> <p>The same goes for a <code>normal double</code> and <code>NumberDecimal</code>.</p> <p><code>NumberInt</code> creates a <code>int32</code> value =&gt; <code>NumberInt(55)</code> and <code>NumberLong</code> creates a <code>int64</code> value =&gt; <code>NumberLong(7489729384792)</code></p> <p>If you just use a number e.g. <code>insertOne({age: 1})</code>, this will get added as a <code>normal double</code> into the database. </p> <p>The reason for this is that the shell is based on <code>JS</code> which only knows <code>float/double</code> values and doesn't differ between <code>integers</code> and <code>floats</code>.</p> <p><code>NumberDecimal</code> creates a high-precision double value e.g. <code>NumberDecimal(\"12.99\")</code> This can be helpful for cases where you need (many) exact decimal places for calculations.</p> <p>When not working with the shell but a MongoDB driver for your app programming language (e.g. PHP, .NET, Node.js, ...), you can use the driver to create these specific numbers.</p> <p>Example for Node.js</p> <p>This will allow you to build a <code>NumberLong</code> value like this </p><pre><code>const Long = require('mongodb').Long;\ndb.collection('wealth')\n    .insert({ value: Long.fromString(\"121949898291\")});\n</code></pre>"},{"location":"mongodb/data-types/#embedded-documents-vs-reference-id","title":"Embedded documents vs reference id","text":""},{"location":"mongodb/data-types/#embedding-is-better-for","title":"Embedding is better for","text":"<ul> <li>Small subdocuments</li> <li>Data that does not change regularly</li> <li>When eventual consistency is acceptable</li> <li>Documents that grow by a small amount</li> <li>Data that you'll often need to perform a second query to fetch Fast reads</li> </ul>"},{"location":"mongodb/data-types/#references-are-better-for","title":"References are better for","text":"<ul> <li>Large subdocuments</li> <li>Volatile data</li> <li>When immediate consistency is necessary</li> <li>Documents that grow a large amount</li> <li>Data that youll often exclude from the results</li> <li>Fast writes</li> </ul> <p>Refference : Data Modeling</p> <p>We can also use aggregation framework for joining.</p> <p>The MongoDB <code>lookup</code> operator, by definition, <code>Performs a left outer join to an unshared collection in the same database to filter in documents from the \"joined\" collection for processing.</code> Simply put, using the MongoDB <code>lookup</code> operator makes it possible to merge data from the document you are running a query on and the document you want the data from.</p> <p>More can be found in the following links</p> <ul> <li>MongoDB Lookup Aggregations: Syntax, Usage &amp; Practical Examples 101</li> <li>$lookup (aggregation)</li> </ul>"},{"location":"mongodb/data-types/#data-validation","title":"Data validation","text":"<p>Though Mongodb is schema less but we real life scenario we must have certain type of structure. We can add validators when we are creating any collection. </p><pre><code>db.createCollection('posts', {\n    validator: {\n      $jsonSchema: {\n        bsonType: 'object',\n        required: ['title', 'text', 'creator', 'comments'],\n        properties: {\n          title: {\n            bsonType: 'string',\n            description: 'must be a string and is required'\n          },\n          text: {\n            bsonType: 'string',\n            description: 'must be a string and is required'\n          },\n          creator: {\n            bsonType: 'objectId',\n            description: 'must be an objectid and is required'\n          },\n          comments: {\n            bsonType: 'array',\n            description: 'must be an array and is required',\n            items: {\n              bsonType: 'object',\n              required: ['text', 'author'],\n              properties: {\n                text: {\n                  bsonType: 'string',\n                  description: 'must be a string and is required'\n                },\n                author: {\n                  bsonType: 'objectId',\n                  description: 'must be an objectid and is required'\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n  });\n</code></pre> <p>If the collection is already created, then we can use run command to add validations and also, we can add validation level </p><pre><code>db.runCommand({\n    collMod: 'posts',\n    validator: {\n      $jsonSchema: {\n        bsonType: 'object',\n        required: ['title', 'text', 'creator', 'comments'],\n        properties: {\n          title: {\n            bsonType: 'string',\n            description: 'must be a string and is required'\n          },\n          text: {\n            bsonType: 'string',\n            description: 'must be a string and is required'\n          },\n          creator: {\n            bsonType: 'objectId',\n            description: 'must be an objectid and is required'\n          },\n          comments: {\n            bsonType: 'array',\n            description: 'must be an array and is required',\n            items: {\n              bsonType: 'object',\n              required: ['text', 'author'],\n              properties: {\n                text: {\n                  bsonType: 'string',\n                  description: 'must be a string and is required'\n                },\n                author: {\n                  bsonType: 'objectId',\n                  description: 'must be an objectid and is required'\n                }\n              }\n            }\n          }\n        }\n      }\n    },\n    validationAction: 'warn'\n  });\n</code></pre> <p>Helpful Articles/ Docs:</p> <ul> <li>MongoDB Limits and Thresholds</li> <li>BSON Types</li> <li>Schema Validation</li> </ul> <p>We can configure mongodb server in with various arguments. We can check all in mongod --help command.</p> <p>We can also use mongod.cfg to put all our configurations in a file and we can put it inside any folder and to we have use that file when we are about to start the server.</p> <p>mongod -f /path/mongod.cfg </p><pre><code>storage:\n  dbPath: \"/your/path/to/the/db/folder\"\nsystemLog:\n  destination: file\n  path: \"/your/path/to/the/logs.log\"\n</code></pre> Reference: Self-Managed Configuration File Options <p>Helpful Articles/ Docs:</p> <ul> <li>More Details about Config Files: Self-Managed Configuration File Options</li> <li>More Details about the Server (mongod) Options: mongod</li> </ul>"},{"location":"mongodb/delete/","title":"delete","text":""},{"location":"mongodb/delete/#introduction","title":"Introduction","text":"<p>To <code>delete</code> any document, we have <code>deleteOne</code> and <code>deleteMany</code> methods.  In the <code>2nd</code> parameter we can also give <code>writeConcerns</code>. </p> <p>delete the first record where name is <code>Abhishek</code> </p><pre><code>db.infos.deleteOne({ name :  \"Abhishek\" })\n</code></pre> <p>delete the all record where age is greater than equal to <code>40</code> </p><pre><code>db.infos.deleteMany({ age :  { $gte : 40} })\n</code></pre> <p>delete the all record where age don't exists </p><pre><code>db.infos.deleteMany({ age :  { $exists : false } })\n</code></pre> <p>We can <code>delete</code> all the documents in a collection by using <code>db.infos.deleteMany({})</code></p> <p>We can <code>drop</code> the collection by <code>db.infos.drop()</code></p> <p>We can <code>drop</code> the database by <code>db.dropDatabase()</code></p>"},{"location":"mongodb/delete/#more-examples","title":"More Examples","text":"<p>Delete one document: </p><pre><code>db.coll.deleteOne({name: \"Max\"})\n</code></pre> <p>Delete many documents with write concern: </p><pre><code>db.coll.deleteMany({name: \"Max\"}, {\"writeConcern\": {\"w\": \"majority\", \"wtimeout\": 5000}})\n</code></pre> <p>Delete all documents in a collection: </p><pre><code>db.coll.deleteMany({}) // WARNING! Deletes all the docs but not the collection itself and its index definitions\n</code></pre> <p>Find one document and delete: </p><pre><code>db.coll.findOneAndDelete({\"name\": \"Max\"})\n</code></pre>"},{"location":"mongodb/geospatial-data/","title":"geospatial data","text":""},{"location":"mongodb/geospatial-data/#introduction","title":"Introduction","text":"<p>We can also store and retrieve geo location <code>(2D)</code> data and use indexes on that. </p> <p>It will be stored as <code>[x,y]</code> where <code>x</code> must be the longitude and <code>y</code> must be the latitude. It follows the geoJSON format only.</p> <pre><code>&gt; db.infos.insertOne({\n    name : \"Home\" , \n    location : { \n        type : \"Point\" , \n        coordinates : [24.0814946,88.2408234,13.38]\n    }\n})\n\n{\n        \"acknowledged\" : true,\n        \"insertedId\" : ObjectId(\"62dcff4c85a6e4bfe5a374cd\")\n}\n</code></pre> <p>To store the coordinates, we must follow this structure of the embed document { location : { type : \"Point\" , coordinates : [24.0814946,88.2408234]}}. We can change the name of field \u201clocation\u201d, but the structure must be same.</p> <p>We can also store area or polygon Let\u2019s create 4 points  </p><pre><code>const p1 = [24.08409, 88.24231]\nconst p2 = [24.09149, 88.24707]\nconst p3 = [24.08879, 88.25578]\nconst p4 = [24.08048, 88.24934]\n\n&gt; db.infos.insertOne({\n        name : \"Gorabazar area\" , \n        location : { \n            type : \"Polygon\" , coordinates : [[p1,p2,p3,p4,p1]]\n        }\n    })\n{\n        \"acknowledged\" : true,\n        \"insertedId\" : ObjectId(\"62dd0e1d85a6e4bfe5a374d3\")\n}\n</code></pre> <p>It is to better to create a geospatial index as most of the geospatial queries require indexing. We can check any points are near to the queried point or not. For that we have a special syntax. </p><pre><code>&gt; db.infos.find({ \n    location : { \n        $near : { $geometry : { type : \"Point\", coordinates : [24,88]}}\n    }\n}).pretty()\n\n{\n        \"_id\" : ObjectId(\"62dcff4c85a6e4bfe5a374cd\"),\n        \"name\" : \"Home\",\n        \"location\" : {\n                \"type\" : \"Point\",\n                \"coordinates\" : [\n                        24.0814946,\n                        88.2408234\n                ]\n        }\n}\n</code></pre> <p>We can also specify other things along side $geometry like $maxDistance and $minDistance. The unit will be in meters. </p><pre><code>&gt; db.infos.find({ \n    location : { \n        $near : { \n            $geometry : { type : \"Point\", coordinates : [24,88]}, \n            $minDistance : 10, $maxDistance : 26809}\n    }\n}).pretty()\n\n&gt; db.infos.find({ \n        location : { \n            $near : { \n                $geometry : { type : \"Point\", coordinates : [24,88]}, \n                $minDistance : 10, \n                $maxDistance : 26810\n            }\n        }\n    }).pretty()\n{\n      \"_id\" : ObjectId(\"62dcff4c85a6e4bfe5a374cd\"),\n        \"name\" : \"Home\",\n        \"location\" : {\n                \"type\" : \"Point\",\n                \"coordinates\" : [\n                        24.0814946,\n                        88.2408234\n                ]\n        }\n}\n</code></pre> <p>To find a place inside any special region or not we can do this. First, we can create our own map (from google maps -&gt; your places -&gt; see all your maps) and create one area or polygon.</p> <p>We can validate all the points are inside of these 4 coordinates or not. In map we will see these 4 points made a rectangle.</p> <p>We will also insert some of the points. </p><pre><code>&gt; db.infos.insertOne({\n    name : \"Murshidabad medical college\" , \n    location : { type : \"Point\" , coordinates : [24.089473,88.2513618]}\n})\n&gt; db.infos.insertOne({\n    name : \"Gorabazar ICI\" , \n    location : { type : \"Point\" , coordinates : [24.0930413,88.2483631]}\n})\n&gt; db.infos.insertOne({\n        name : \"Mary immaculate school\" , \n        location : { type : \"Point\" , coordinates : [24.0930413,88.2483631]}\n    })\n&gt; db.infos.insertOne({\n        name : \"Berhampore head post office\" , \n        location : { type : \"Point\" , coordinates : [24.0947532,88.2510873]}\n    })\n&gt; db.infos.insertOne({\n        name : \"Mohon cinema hall\" , \n        location : { type : \"Point\" , coordinates : [24.0947532,88.2510873]}\n    })\n</code></pre> <p>Again, we must follow some specific syntax for with in query. </p><pre><code>&gt; db.infos.find({ \n    location : { \n        $geoWithin : { \n            $geometry : { type : \"Polygon\", coordinates : [[p1,p2,p3,p4,p1]]}\n        }\n    }\n})\n</code></pre> <p>Keyword is $geoWithin and type is Polygon and coordinates will be in 2nd layer of nested arrays and the first and the last point should be same.</p> <p>We can also search for the opposite query. We can find an poly where a point belongs or not. </p><pre><code>&gt; db.infos.find({ \n    location : { \n        $geoIntersects : { \n            $geometry : { type : \"Point\" , coordinates : [24.089473,88.2513618] } }\n    }\n})\n</code></pre> <p>We can also search in circle within a radius. </p><pre><code>&gt; db.infos.find({ \n    location : { \n        $geoWithin : { \n            $centerSphere : [[24.089473, 88.2513618], 1/6378.1]}\n    }\n})\n</code></pre> Where 1st one is the 2d coordinate and 2nd one is radius. 1 is in kilometre. 6378.1 is the constant. Check this on official documentation."},{"location":"mongodb/introduction/","title":"introduction","text":""},{"location":"mongodb/introduction/#what-is-mongodb","title":"What is MongoDB?","text":"<p>MongoDB is a document-oriented NoSQL database used to store large amounts of data as documents. It has collections similar to tables in relational databases. It has no schema. We can use JSON objects to store data, but behind the scenes, the MongoDB server stores this JSON in binary format.</p>"},{"location":"mongodb/introduction/#what-is-mongod","title":"What is <code>mongod</code>?","text":"<p>It is an executable file used to start the MongoDB server locally.</p>"},{"location":"mongodb/introduction/#what-is-mongosh","title":"What is <code>mongosh</code>?","text":"<p>It is a MongoDB shell used to connect to MongoDB to execute queries.</p> <p>We can specify the location where we want to save our data locally. It should have <code>data</code> and <code>logs</code> folders inside it. Then start the server like the following: </p><pre><code>mongod --dbpath /path/data --logpath /path/logs/mongo.log\n</code></pre>"},{"location":"mongodb/introduction/#connect-to-mongodb-shell","title":"Connect to MongoDB Shell","text":"<pre><code>mongosh // connects to mongodb://127.0.0.1:27017 by default\nmongosh \"mongodb+srv://cluster-name.abcde.mongodb.net/&lt;dbname&gt;\" --username &lt;username&gt; // MongoDB Atlas\nmongosh --host &lt;host&gt; --port &lt;port&gt; --authenticationDatabase admin -u &lt;user&gt; -p &lt;pwd&gt; # omit the password if you want a prompt\nmongosh \"mongodb://&lt;user&gt;:&lt;password&gt;@192.168.1.1:27017\"\nmongosh \"mongodb://192.168.1.1:27017\"\nmongosh \"mongodb+srv://cluster-name.abcde.mongodb.net/&lt;dbname&gt;\" --apiVersion 1 --username &lt;username&gt; # MongoDB Atlas\n</code></pre>"},{"location":"mongodb/introduction/#install-mongodb","title":"Install MongoDB","text":"<p>Install MongoDB Community Edition</p>"},{"location":"mongodb/introduction/#windows","title":"Windows","text":"<p>How do I start/stop MongoDB from running in the background in Windows?</p> <p>In Windows, there is an option to start MongoDB as a service so it will be running all the time in the background. One-liner to start or stop MongoDB service using the command line in Windows:</p> <ul> <li>To start the service use: <code>NET START MONGODB</code></li> <li>To stop the service use: <code>NET STOP MONGODB</code></li> </ul>"},{"location":"mongodb/introduction/#macoslinux","title":"MacOS/Linux","text":"<p>How do I start/stop MongoDB from running in the background in macOS/Linux?</p> <p>The <code>--fork</code> option is used to run MongoDB in the background. </p><pre><code>mongod --port 8888 --dbpath /Users/Shared/data/db --logpath /Users/Shared/log/mongo.log --fork\n</code></pre> We can shut down MongoDB by first switching to the <code>admin</code> database, then use this command: <pre><code>db.shutdownServer()\n</code></pre>"},{"location":"mongodb/introduction/#docker","title":"Docker","text":"<p>How do I start/stop mongodb from docker </p><pre><code>docker run \\\n  --rm \\\n  --name mongodb \\\n  -v ~/mongodb-data:/data/db \\\n  -e MONGO_INITDB_ROOT_USERNAME=admin \\\n  -e MONGO_INITDB_ROOT_PASSWORD=password \\\n  -p 27017:27017 \\\n  mongo\n</code></pre>"},{"location":"mongodb/introduction/#prod-deployments","title":"Prod deployments","text":"<p>We can create production level Replica Set and Sharded Cluster</p>"},{"location":"mongodb/introduction/#common-commands","title":"Common Commands","text":""},{"location":"mongodb/introduction/#setup","title":"Setup","text":"<p>MongoDB uses <code>BSON</code> instead of <code>JSON</code> to store data. The maximum size of a document can be <code>16 MB</code>.</p> <p>Show all databases: </p><pre><code>show dbs\n</code></pre> <p>Create or use a database: </p><pre><code>use &lt;db_name&gt;\n</code></pre> <p>Remove the database: </p><pre><code>db.dropDatabase()\n</code></pre> <p>Show all collections: </p><pre><code>show collections\n</code></pre> <p>Create collections: </p><pre><code>db.createCollection(\"coll\") // creates the collection `coll`\n</code></pre> <p>Drop collections: </p><pre><code>db.coll.drop()    // removes the collection `coll`\n</code></pre> <p>Create a collection with a <code>$jsonschema</code> validator: </p><pre><code>// Create collection with a $jsonschema\ndb.createCollection(\"hosts\", {\n    validator: {$jsonSchema: {\n        bsonType: \"object\",\n        required: [\"email\"], // required fields\n        properties: {\n            // All possible fields\n            phone: {\n                bsonType: \"string\",\n                description: \"must be a string and is required\"\n            },\n            email: {\n                bsonType: \"string\",\n                pattern: \"@mongodb\\.com$\",\n                description: \"must be a string and match the regular expression pattern\"\n            },\n        }\n    }}\n})\n\ndb.createCollection(\"contacts\", {\n   validator: {$jsonSchema: {\n      bsonType: \"object\",\n      required: [\"phone\"],\n      properties: {\n         phone: {\n            bsonType: \"string\",\n            description: \"must be a string and is required\"\n         },\n         email: {\n            bsonType: \"string\",\n            pattern: \"@mongodb\\.com$\",\n            description: \"must be a string and match the regular expression pattern\"\n         },\n         status: {\n            enum: [ \"Unknown\", \"Incomplete\" ],\n            description: \"can only be one of the enum values\"\n         }\n      }\n   }}\n})\n</code></pre> <p>Run JavaScript File: </p><pre><code>load(\"script.js\")\n</code></pre> <p>Get collection statistics: </p><pre><code>db.coll.stats()\n</code></pre> <p>Get collection storage size: </p><pre><code>db.coll.storageSize()\n</code></pre> <p>Get total index size of a collection: </p><pre><code>db.coll.totalIndexSize()\n</code></pre> <p>Get total size of a collection: </p><pre><code>db.coll.totalSize()\n</code></pre> <p>Validate a collection: </p><pre><code>db.coll.validate({full: true})\n</code></pre> <p>Rename a collection: </p><pre><code>db.coll.renameCollection(\"new_coll\", true) // 2nd parameter to drop the target collection if exists\n</code></pre>"},{"location":"mongodb/introduction/#insert","title":"Insert","text":"<p>Insert one document into a collection: </p><pre><code>db.products.insertOne({\n    name: \"Abhishek Ghosh\", \n    age: 24\n})\n</code></pre> This will create a document in the <code>products</code> collection. After inserting one document, it will give an <code>id</code> and acknowledgment. We can also insert nested documents. <p>Insert many documents into a collection: </p><pre><code>db.coll.insertMany([\n    {name: \"Navi\", age: 25}, \n    {name: \"Alice\", age: 30}\n])\n</code></pre> <p>By default, MongoDB adds a unique <code>ObjectId</code> to every document, and we can search items with that. MongoDB also creates a default index with this <code>_id</code> by default. We can also add our <code>_id</code> like the following: </p><pre><code>db.products.insertOne({_id: \"abhishek-test-0001\", name: \"Abhishek Ghosh\"})\n</code></pre>"},{"location":"mongodb/introduction/#find","title":"Find","text":"<p>Show all documents in a collection: </p><pre><code>db.products.find()\n</code></pre> <p>List all documents with name \"Navi\" and age 25, and return only one document: </p><pre><code>db.coll.find({\n    name: \"Navi\", \n    age: 25\n}).limit(1)\n</code></pre> <p>Show documents in a JSON structure: </p><pre><code>db.products.find().pretty()\n</code></pre> <p>Search any document using <code>_id</code>: </p><pre><code>db.products.find({_id: ObjectId('62a6ff6edb132197c5e887a0')})\n</code></pre> <p>Count all documents in 'coll' collection: </p><pre><code>db.coll.count()\n</code></pre> <p>Count all documents with name \"Navi\": </p><pre><code>db.coll.count({name: \"Navi\"})\n</code></pre> <p>Find document and show execution stats: </p><pre><code>db.coll.find({name: \"Navi\"}).explain(\"executionStats\")\n</code></pre>"},{"location":"mongodb/introduction/#update","title":"Update","text":"<p>Update all documents with name \"Navi\" and set age to 26: </p><pre><code>db.coll.update({name: \"Navi\"}, {$set: {age: 26}})\n</code></pre> <p>Update all documents with name \"Navi\" and increment age by 1: </p><pre><code>db.coll.update({name: \"Navi\"}, {$inc: {age: 1}})\n</code></pre> <p>Update all documents with name \"Navi\" and set age to null: </p><pre><code>db.coll.update({name: \"Navi\"}, {$unset: {age: 1}})\n</code></pre> <p>Remove age field from all documents with age field: </p><pre><code>db.coll.updateMany({age: {$exists: true}}, {$unset: {age: \"\"}})\n</code></pre>"},{"location":"mongodb/introduction/#delete","title":"Delete","text":"<p>Remove all documents with name \"Navi\": </p><pre><code>db.coll.deleteMany({name: \"Navi\"})\n</code></pre> <p>Remove one document with name \"Navi\": </p><pre><code>db.coll.deleteOne({name: \"Navi\"})\n</code></pre>"},{"location":"mongodb/introduction/#indexes","title":"Indexes","text":"<p>List indexes: </p><pre><code>db.coll.getIndexes()\n</code></pre> <p>List index keys: </p><pre><code>db.coll.getIndexKeys()\n</code></pre> <p>Create index: </p><pre><code>db.coll.createIndex({\"name\": 1})\n</code></pre> <p>Create a compound index: </p><pre><code>db.coll.createIndex({\"name\": 1, \"date\": 1})\n</code></pre> <p>Drop index: </p><pre><code>db.coll.dropIndex(\"name_1\")\n</code></pre>"},{"location":"mongodb/introduction/#acid-compliance-in-mongodb","title":"ACID Compliance in MongoDB","text":"ACID Property MongoDB Implementation Atomicity MongoDB ensures atomicity at the single-document level, meaning changes to a single document are always atomic. Starting with version 4.0, MongoDB provides multi-document transactions and guarantees the atomicity of the transactions. Consistency MongoDB uses schema validation, a feature that allows you to define the specific structure of documents in each MongoDB collection. If the document structure deviates from the defined schema, MongoDB will return an error. This is how MongoDB enforces its version of consistency, however, it's optional and less rigid than in traditional SQL databases. Isolation MongoDB isolates write operations on a per-document level. By default, clients do not wait for acknowledgement of write operations. However, users can configure write concern to guarantee a desired level of isolation. Multi-document transactions in MongoDB are isolated across participating nodes for the duration of each transaction. Durability MongoDB allows you to specify the level of durability when writing documents. You can choose to wait until the data is written to a certain number of servers, or even to the disk. This is configurable by setting the write concern when writing data."},{"location":"mongodb/introduction/#tutorials","title":"Tutorials","text":""},{"location":"mongodb/introduction/#website","title":"Website","text":"<ul> <li>neetcode</li> <li>MongoDB Developer</li> </ul>"},{"location":"mongodb/introduction/#youtube","title":"YouTube","text":"<ul> <li>MongoDB Crash Course</li> </ul>"},{"location":"mongodb/introduction/#udemy","title":"Udemy","text":"<ul> <li>MongoDB - The Complete Developer's Guide</li> <li>MongoDB: A Complete Database Administration Course</li> </ul>"},{"location":"mongodb/operators/","title":"operators","text":""},{"location":"mongodb/operators/#complex-operators","title":"Complex Operators","text":""},{"location":"mongodb/operators/#query-and-projection-operators","title":"Query and Projection Operators","text":"<p>$eq: Matches values that are equal to a specified value. </p><pre><code>{ field: { $eq: value } }\n</code></pre> <p>$gt: Matches values that are greater than a specified value. </p><pre><code>{ field: { $gt: value } }\n</code></pre> <p>$gte: Matches values that are greater than or equal to a specified value. </p><pre><code>{ field: { $gte: value } }\n</code></pre> <p>$lt: Matches values that are less than a specified value. </p><pre><code>{ field: { $lt: value } }\n</code></pre> <p>$lte: Matches values that are less than or equal to a specified value. </p><pre><code>{ field: { $lte: value } }\n</code></pre> <p>$ne: Matches all values that are not equal to a specified value. </p><pre><code>{ field: { $ne: value } }\n</code></pre> <p>$in: Matches any value in the specified array. </p><pre><code>{ field: { $in: [value1, value2, ...] } }\n</code></pre> <p>$nin: Matches none of the values specified in an array. </p><pre><code>{ field: { $nin: [value1, value2, ...] } }\n</code></pre>"},{"location":"mongodb/operators/#logical-operators","title":"Logical Operators","text":"<p>$or: Joins query clauses with a logical OR, returns all documents that match the conditions of either clause. </p><pre><code>{ $or: [ { clause1 }, { clause2 } ] }\n</code></pre> <p>$and: Joins query clauses with a logical AND, returns all documents that match the conditions of both clauses. </p><pre><code>{ $and: [ { clause1 }, { clause2 } ] }\n</code></pre> <p>$not: Inverts the effect of a query expression and returns documents that do not match the query expression. </p><pre><code>{ field: { $not: { clause } } }\n</code></pre> <p>$nor: Joins query clauses with a logical NOR, returns all documents that fail to match both clauses. </p><pre><code>{ $nor: [ { clause1 }, { clause2 } ] }\n</code></pre>"},{"location":"mongodb/operators/#array-operators","title":"Array Operators","text":"<p>$all: Matches arrays that contain all elements specified in the query. </p><pre><code>{ field: { $all: [value1, value2, ...] } }\n</code></pre> <p>$elemMatch: Selects documents if element in the array field matches all the specified $elemMatch conditions. </p><pre><code>{ field: { $elemMatch: { clause1, clause2, ... } } }\n</code></pre> <p>$size: Selects documents if the array field is a specified size. </p><pre><code>{ field: { $size: size } }\n</code></pre>"},{"location":"mongodb/operators/#update-operators","title":"Update Operators","text":"<p>$set: Sets the value of a field in a document. </p><pre><code>{ $set: { field: value } }\n</code></pre> <p>$unset: Removes the specified field from a document. </p><pre><code>{ $unset: { field: \"\" } }\n</code></pre> <p>$inc: Increments the value of the field by the specified amount. </p><pre><code>{ $inc: { field: amount } }\n</code></pre> <p>$mul: Multiplies the value of the field by the specified amount. </p><pre><code>{ $mul: { field: amount } }\n</code></pre> <p>$push: Appends a specified value to an array. </p><pre><code>{ $push: { field: value } }\n</code></pre> <p>$pop: Removes the first or last element of an array. </p><pre><code>{ $pop: { field: 1 } } // Removes the last element\n{ $pop: { field: -1 } } // Removes the first element\n</code></pre> <p>$pull: Removes all array elements that match a specified query. </p><pre><code>{ $pull: { field: { clause } } }\n</code></pre>"},{"location":"mongodb/operators/#aggregation-operators","title":"Aggregation Operators","text":"<p>$match: Filters the documents to pass only documents that match the specified condition(s) to the next pipeline stage. </p><pre><code>{ $match: { clause } }\n</code></pre> <p>$group: Groups input documents by a specified identifier expression and applies the accumulator expression(s), if specified, to each group. </p><pre><code>{ $group: { _id: \"$field\", total: { $sum: \"$amount\" } } }\n</code></pre> <p>$project: Passes along the documents with only the specified fields to the next stage in the pipeline. </p><pre><code>{ $project: { field1: 1, field2: 1, _id: 0 } }\n</code></pre> <p>$sort: Sorts all input documents and outputs them to the next stage in the specified sort order. </p><pre><code>{ $sort: { field: 1 } } // Ascending order\n{ $sort: { field: -1 } } // Descending order\n</code></pre> <p>$limit: Passes the first n documents unmodified to the pipeline where n is the specified limit. </p><pre><code>{ $limit: n }\n</code></pre>"},{"location":"mongodb/read/","title":"read","text":""},{"location":"mongodb/read/#introduction","title":"Introduction","text":"<p>Following are the components of mongodb reads</p> <ul> <li>Methods, Filters and Operators</li> <li>Query Selectors</li> <li>Projection Operators</li> </ul> <p>There are two methods</p> <ul> <li><code>find</code>: returns all the documents which satisfies the criteria (basically it returns the cursor object)</li> <li><code>findOne</code>: it returns a first document that satisfies the criteria</li> </ul> <p>find method gives a cursor of 20 objects</p> <p>Examples </p><pre><code>&gt; db.products.findOne({age:24}) -&gt;  to get the document where age is 24\n&gt; db.products.findOne({age:{$gt:24}}) -&gt; to get the document where age is greater than 24\n</code></pre> <p>Operators are reserved fields started with dollar like $gt, $gte, $lt, $lte</p> <p>Query Selectors</p> <ul> <li>Comparison</li> <li>Evaluation</li> <li>Logical</li> <li>Array</li> <li>Element</li> <li>Comments</li> <li>Geospatial</li> </ul> <p>Projection Operator</p> <ul> <li>$</li> <li>$elemMatch</li> <li>$meta</li> <li>$slice</li> </ul> <p>first it will search the document where name is \"Under the Dome\" then it only return name, type and language </p><pre><code>db.infos.find({\"name\": \"Under the Dome\"},{\"name\":1,\"type\":1,\"language\":1})\n</code></pre> <p>runtime equal to 60, both of them will work same </p><pre><code>db.infos.findOne({runtime:60})\n\ndb.infos.findOne({runtime:{$eq:60}})\n</code></pre> <p>runtime not equal to 60 </p><pre><code>db.infos.findOne({runtime:{$ne:60}}) \n</code></pre> <p>runtime greater than 60 </p><pre><code>db.infos.findOne({runtime:{$gt:60}})\n</code></pre> <p>runtime greater than equal to 60 </p><pre><code>db.infos.findOne({runtime:{$gte:60}})\n</code></pre> <p>runtime less than 60 </p><pre><code>db.infos.findOne({runtime:{$lt:60}})\n</code></pre> <p>runtime less than equal to 60 </p><pre><code>db.infos.findOne({runtime:{$lte:60}}) \n</code></pre> <p>it will find all the documents where runtime is either 30 or 42 </p><pre><code>db.infos.find({runtime: {$in: [30,42]}}) \n</code></pre> <p>it will find all the documents where runtime is neither 30 nor 42 </p><pre><code>db.infos.find({runtime: {$nin: [30,42]}}) \n</code></pre> <p>average is a field which is inside of rating, so to querying anything in average we can use something like this layer1.layer2.layer3.targetField then our query operator </p><pre><code>db.infos.findOne({\"rating.average\": {$gt: 9}}) \n</code></pre> <p>here genres is a array. If we search for this, it will not equate as a string it will check that genres contain Drama or not </p><pre><code>db.infos.findOne({\"genres\": \"Drama\"}) \n</code></pre> <p><code>$or</code> operator takes an array of queries. Here average is either greater than 8 or less than 7. We can combine more than two queries. </p><pre><code>db.infos.find({$or: [{\"rating.average\": {$gt: 8}}, {\"rating.average\": {$lt: 7}}]}) \n</code></pre> <p><code>$nor</code> operator takes an array of queries. Here average is neither greater than 8 nor less than 7. We can combine more than two queries. </p><pre><code>db.infos.find({$nor : [{\"rating.average\": {$gt: 8}}, {\"rating.average\": {$lt: 7}}]}) \n</code></pre> <p><code>$and</code> operator takes an array of queries. Here average is less than 8 and greater than 7. We can combine more than two queries. We have a short cut for and query. </p><pre><code>db.infos.find({$and : [{\"rating.average\": {$lt:8}},{\"rating.average\": {$gt:7}}]}) \n</code></pre> <p>these two queries are same as mongodb by default does the and operation and equal to operation </p><pre><code>db.infos.find({$and : [{\"rating.average\": {$lt:8}},{\"runtime\": {$gte:60}}]})\n\ndb.infos.find({\"rating.average\": {$lt:8}, \"runtime\": {$gte:60}})\n</code></pre> <p>we have also <code>$not</code> operator that we can use like this. <code>$not</code> is just like another wrapper to the existing query</p> <p>not of this query <code>db.infos.find({\"rating.average\": {$lt: 8}}).count()</code> will be <code>db.infos.find({\"rating.average\": {$not :{$lt: 8}}}).count()</code></p> <p>There are two element type operators <code>$exist</code> and <code>$type</code></p> <p>As mongodb is schemaless so sometimes there may be a case a field may or may not be exist so we can check that a field is exist or not like this:</p> <p>age field exists </p><pre><code>db.users.findOne({\"age\": {$exists: true}})\n</code></pre> <p>We can use exists with another query as well</p> <p>age field exists and greater than 30 </p><pre><code>db.users.findOne({\"age\": {$exists: true, $gte: 30}})\n</code></pre> <p>age field exists and not equal to null </p><pre><code>db.users.findOne({\"age\": {$exists: true, $ne: null}}) \n</code></pre> <p>As mongodb is schemaless so sometimes there may be a case a field may or may not have the same data type for all the document so we can check that a field has the datatype or not with <code>$type</code></p> <p>phone no is double in which document </p><pre><code>db.users.findOne({\"phoneNo\": {$type: \"double\"}}) \n</code></pre> <p>phone no is string in which document </p><pre><code>db.users.findOne({\"phoneNo\": {$type: \"string\"}}) \n</code></pre> <p>phone no is string or double in which document. We can use array. It will act as OR operator here </p><pre><code>db.users.findOne({\"phoneNo\": {$type: [\"double\", \"string\"]}})\n</code></pre> <p>It will use regex to search any document have the musical word in the summary or not. But it is not that efficient better to use text indexing </p><pre><code>db.infos.find({summary: {$regex: /musical/}}) \n</code></pre> <p>it will search all the documents where weight is greater that runtime. We can use $expr like this where it will take the query inside it.  </p><pre><code>db.infos.find({$expr: {$gt: [\"$weight\", \"$runtime\"]}}) \n</code></pre> <p>We can use if, then an inside $cond and the $expr will evaluate everything.</p>"},{"location":"mongodb/read/#querying-to-arrays","title":"Querying to Arrays","text":"<p>Let's say experience is an array having many fields like college name, company name, start date end date etc</p> <p>it will search the document where in experiences array there will be a object in which companyName field will be Kreeti </p><pre><code>db.products.find({\"experiences.companyName\": \"Kreeti\"}) \n</code></pre> <p>We can use dot operator with array and embedded documents</p> <p>find all the documents where experience is length of 3 </p><pre><code>db.products.find({\"experiences\": {$size: 3}}) \n</code></pre> <p><code>$size</code> operator takes only equality it will not work with <code>$gt</code> or <code>$lt</code> like the following query</p> <p>It will give us the exception. </p><pre><code>db.products.find({\"experiences\": {$size: {$gt: 2}}}) \n</code></pre> <p>It will only search for the documents where genres is <code>[\"Drama\", \"Crime\", \"Thriller\"]</code> particularly in this order but if the order does not matter for us then we can use <code>$all</code> </p><pre><code>db.infos.find({genres: [\"Drama\", \"Crime\", \"Thriller\"]}) \n</code></pre> <p>It will search for all the documents where these three items <code>[\"Drama\", \"Crime\", \"Thriller\"]</code> are there in the genres array. </p><pre><code>db.infos.find({genres: {$all: [\"Drama\", \"Crime\", \"Thriller\"]}}) \n</code></pre> <p>Certainly, these two queries will not give us the same result: </p><pre><code>db.infos.find({genres: {$all: [\"Drama\", \"Crime\"]}}).count() -&gt; 47\n\ndb.infos.find({genres: [\"Drama\", \"Crime\"]}).count() -&gt; 12\n</code></pre> <p>Find how many persons are working in TCS or not. Probable answers are : </p><pre><code>db.products.find({\"experiences.companyName\": \"TCS\",\"experiences.currentlyInHere\": true}).count()\n\ndb.products.find({$and: [{\"experiences.companyName\": \"TCS\"}, {\"experiences.currentlyInHere\": true}]}).count()\n</code></pre> <p>If we use this query ideally it should return <code>1</code> as there is only one document where in one <code>experience</code> item <code>companyName</code> is <code>TCS</code> and <code>currentlyHere</code> is <code>true</code> but this query does not work like that it will check in the <code>arrays</code> that if any object has the <code>companyName</code> as <code>TCS</code> and <code>currentlyHere</code> is <code>true</code>. It does not need to be the same object in the array. Here we could use the <code>$elemMatch</code>. It will search for all the queries in the same item of the array.</p> <p>We can achieve our requirement of any person who is currently working in TCS or not with the below query: <code>$elemMatch</code> will match all the queries for every element in the array. </p><pre><code>db.products.find({experiences: {$elemMatch: {companyName: \"TCS\",currentlyInHere: true}}}).count()\n</code></pre>"},{"location":"mongodb/read/#cursor","title":"Cursor","text":"<p>In <code>MongoDB</code>, the <code>find()</code> method return the <code>cursor</code>, now to access the document we need to iterate the <code>cursor</code>. In the <code>mongo shell</code>, if the <code>cursor</code> is not assigned to a <code>var</code> keyword then the <code>mongo shell</code> automatically iterates the <code>cursor</code> up to <code>20</code> documents. <code>MongoDB</code> also allows you to iterate cursor manually. So, to iterate a cursor manually simply assign the cursor return by the <code>find()</code> method to the <code>var</code> keyword or JavaScript variable.</p> <p>Note: If a <code>cursor</code> inactive for <code>10 min</code>, then <code>MongoDB</code> server will automatically close that cursor.</p> <p>It will fetch the <code>cursor</code> of first 20 elements. </p><pre><code>db.infos.find().pretty() \n</code></pre> <p>It will exhaust the <code>cursor</code> and make all the documents as <code>array</code> of objects </p><pre><code>db.infos.find().toArray()\n</code></pre> <p>It give us the <code>count</code> of all the element </p><pre><code>db.infos.find().count() \n</code></pre> <p>it will say if the <code>cursor</code> has exhausted or not </p><pre><code>db.infos.find().hasNext()\n</code></pre> <p>it will give the current <code>20</code> elements of the <code>cursor</code> </p><pre><code>db.infos.find().next() \n</code></pre> <p><code>printjson</code> is a method in <code>shell</code>. <code>forEach</code> is a function on the <code>cursor</code> </p><pre><code>db.infos.find().forEach((doc) =&gt; printjson(doc)) \n</code></pre> <p>It will <code>sort</code> all the elements on <code>average</code> element on rating. </p><pre><code>db.infos.find().sort({\"rating.average\" :1}) \n</code></pre> <p>It will <code>sort</code> all the elements on <code>average</code> element on rating and then runtime but backwards </p><pre><code>db.infos.find().sort({\"rating.average\" :1, \"runtime\": -1})\n</code></pre> <p>It will sort all the elements on <code>average</code> element on rating then skip the first 10 elements </p><pre><code>db.infos.find().sort({\"rating.average\" :1}).skip(10)  \n</code></pre> <p>It will sort all the elements on <code>average</code> element on rating then only show the first <code>2</code> elements </p><pre><code>db.infos.find().sort({\"rating.average\" :1}).limit(2) \n</code></pre> <p>It will sort all the elements on <code>average</code> element on rating then <code>skip 2 elements</code> and show only <code>2</code> elements </p><pre><code>db.infos.find().sort({\"rating.average\" :1}).skip(2).limit(2) \n</code></pre> <p>It will show only the <code>name</code> and the <code>_id</code> of first <code>20</code> documents. <code>_id</code> is shown by default. </p><pre><code>db.infos.find({},{name: 1}) \n</code></pre> <p>It will show only the name of first <code>20</code> documents. </p><pre><code>db.infos.find({},{_id: 0, name: 1}) \n</code></pre> <p>It will show only the <code>name</code> and <code>schedule</code> object with only <code>time</code> field and the <code>_id</code> of first <code>20</code> documents. </p><pre><code>db.infos.find({},{name: 1, \"schedule.time\": 1}) \n</code></pre> <p>It will first search for the documents with <code>genres</code> with <code>Thriller</code> then with <code>projection</code> it will show only the <code>first</code> element of genres array </p><pre><code>db.infos.find({genres: \"Thriller\"},{\"genres.$\": 1}) \n</code></pre> <p>It will first search for the documents with genres array with <code>Drama and Action</code> then with projection it will show only the <code>first</code> element of genres array </p><pre><code>db.infos.find({genres: {$all : [\"Drama\",\"Action\"]}},{\"genres.$\": 1}) \n</code></pre> <p>Here Querying and projecting works independently. First it will search for genres array with <code>Drama and Action</code> then with <code>projection</code> it will show only the array with <code>Horror</code> present or not. </p><pre><code>db.infos.find({genres: {$all : [\"Drama\",\"Action\"]}},{\"genres\" : {$elemMatch: {$eq: \"Horror\"}}}) \n</code></pre> <p><code>$slice</code> only works array while projection. <code>{$slice: 2}</code> will slice the first <code>2</code> elements of the array. </p><pre><code>db.infos.find({}, {genres: {$slice: 2}, name: 1}) \n</code></pre> <p><code>{$slice: [1,3]}</code> will slice the <code>1st</code> to <code>3rd</code> elements of the array. </p><pre><code>db.infos.find({},{genres: {$slice: [1,3]},name: 1}) \n</code></pre>"},{"location":"mongodb/read/#more-examples","title":"More Examples","text":"<p>Find one document: </p><pre><code>db.coll.findOne()\n</code></pre> <p>Find all documents (returns a cursor - show 20 results - \"it\" to display more): </p><pre><code>db.coll.find()\n</code></pre> <p>Find all documents and pretty print: </p><pre><code>db.coll.find().pretty()\n</code></pre> <p>Find documents with specific criteria (implicit logical \"AND\"): </p><pre><code>db.coll.find({name: \"Max\", age: 32})\n</code></pre> <p>Find documents with a specific date: </p><pre><code>db.coll.find({date: ISODate(\"2020-09-25T13:57:17.180Z\")})\n</code></pre> <p>Find documents with specific criteria and explain execution stats: </p><pre><code>db.coll.find({name: \"Max\", age: 32}).explain(\"executionStats\")\n</code></pre> <p>Find distinct values for a field: </p><pre><code>db.coll.distinct(\"name\")\n</code></pre> <p>Count documents with specific criteria (accurate count): </p><pre><code>db.coll.countDocuments({age: 32})\n</code></pre> <p>Estimate document count based on collection metadata: </p><pre><code>db.coll.estimatedDocumentCount()\n</code></pre> <p>Find documents with comparison operators: </p><pre><code>db.coll.find({\"year\": {$gt: 1970}})\ndb.coll.find({\"year\": {$gte: 1970}})\ndb.coll.find({\"year\": {$lt: 1970}})\ndb.coll.find({\"year\": {$lte: 1970}})\ndb.coll.find({\"year\": {$ne: 1970}})\ndb.coll.find({\"year\": {$in: [1958, 1959]}})\ndb.coll.find({\"year\": {$nin: [1958, 1959]}})\n</code></pre> <p>Find documents with logical operators: </p><pre><code>db.coll.find({name: {$not: {$eq: \"Max\"}}})\ndb.coll.find({$or: [{\"year\": 1958}, {\"year\": 1959}]})\ndb.coll.find({$nor: [{price: 1.99}, {sale: true}]})\ndb.coll.find({\n  $and: [\n    {$or: [{qty: {$lt :10}}, {qty :{$gt: 50}}]},\n    {$or: [{sale: true}, {price: {$lt: 5 }}]}\n  ]\n})\n</code></pre> <p>Find documents with element operators: </p><pre><code>db.coll.find({name: {$exists: true}})\ndb.coll.find({\"zipCode\": {$type: 2 }})\ndb.coll.find({\"zipCode\": {$type: \"string\"}})\n</code></pre> <p>Aggregation Pipeline: </p><pre><code>db.coll.aggregate([\n  {$match: {status: \"A\"}},\n  {$group: {_id: \"$cust_id\", total: {$sum: \"$amount\"}}},\n  {$sort: {total: -1}}\n])\n</code></pre> <p>Text search with a \"text\" index: </p><pre><code>db.coll.find({$text: {$search: \"cake\"}}, {score: {$meta: \"textScore\"}}).sort({score: {$meta: \"textScore\"}})\n</code></pre> <p>Find documents with regex: </p><pre><code>db.coll.find({name: /^Max/})   // regex: starts by letter \"M\"\ndb.coll.find({name: /^Max$/i}) // regex case insensitive\n</code></pre> <p>Find documents with array operators: </p><pre><code>db.coll.find({tags: {$all: [\"Realm\", \"Charts\"]}})\ndb.coll.find({field: {$size: 2}}) // impossible to index - prefer storing the size of the array &amp; update it\ndb.coll.find({results: {$elemMatch: {product: \"xyz\", score: {$gte: 8}}}})\n</code></pre> <p>Projections: </p><pre><code>db.coll.find({\"x\": 1}, {\"actors\": 1})               // actors + _id\ndb.coll.find({\"x\": 1}, {\"actors\": 1, \"_id\": 0})     // actors\ndb.coll.find({\"x\": 1}, {\"actors\": 0, \"summary\": 0}) // all but \"actors\" and \"summary\"\n</code></pre> <p>Sort, skip, limit: </p><pre><code>db.coll.find({}).sort({\"year\": 1, \"rating\": -1}).skip(10).limit(3)\n</code></pre> <p>Read Concern: </p><pre><code>db.coll.find().readConcern(\"majority\")\n</code></pre> <p>Since shell is made of JS so we can use JS function For reference: Cursor Methods</p>"},{"location":"mongodb/update/","title":"update","text":""},{"location":"mongodb/update/#introduction","title":"Introduction","text":"<p>In the Users db Info collection all the documents in the following type</p> <p></p><pre><code>{\n  \"_id\": {\n    \"$oid\": \"62ac4ff719cc703713ba43c0\"\n  },\n  \"name\": \"Max\",\n  \"hobbies\": [\n    {\n      \"title\": \"Sports\",\n      \"frequency\": 3\n    },\n    {\n      \"title\": \"Cooking\",\n      \"frequency\": 6\n    }\n  ],\n  \"phone\": 131782734\n}\n</code></pre> But the object with name chris has the different type of <code>hobbies</code> array <p>So, we need to update the <code>hobbies</code>. We have two methods for update any object <code>updateOne</code> and <code>updateMany</code>. The names are self-explanatory.</p> <p>The <code>update</code> method takes two mandatory input one is <code>filter</code> for search and <code>what to update</code>.</p> <p><code>$set</code> keyword is used to set the change the field value. Other fields will be untouched.</p> <pre><code>&gt; db.infos.updateOne(\n    {\"name\" : \"Chris\"},\n    { $set: \n        {\"hobbies\": [\n            {title:\"Sports\",frequency:5},\n            {title:\"Cooking\",frequency:3},\n            {title:\"Hiking\",frequency:1}\n        ]}\n    }\n)\n{ \"acknowledged\" : true, \"matchedCount\" : 1, \"modifiedCount\" : 1 } \n\n## If I again run the same query then the modifiedCount will be 0\n{ \"acknowledged\" : true, \"matchedCount\" : 1, \"modifiedCount\" : 0 }\n</code></pre> <p>We can update multiple documents at the same time </p><pre><code>&gt; db.infos.updateMany(\n    {\"hobbies.title\": \"Sports\"},\n    {$set: {isSporty: true}}\n)\n{ \"acknowledged\" : true, \"matchedCount\" : 3, \"modifiedCount\" : 3 }\n</code></pre> With <code>$set</code> operator we can change more than one field at a time as well. <p>We also have incrementor or decrement operator as these two are very common operation. </p><pre><code>&gt; db.infos.updateOne(\n    {name: \"Manuel\"}, \n    { $inc : { age : 1 }}\n)\n{ \"acknowledged\" : true, \"matchedCount\" : 1, \"modifiedCount\" : 1 }\n</code></pre> <p>With <code>$inc</code> we can also decrement. </p><pre><code>&gt; db.infos.updateOne(\n    { name: \"Manuel\" } , \n    { \n        $inc : { age :  -1 } , \n        $set : { isSporty : false }\n    }\n)\n{ \"acknowledged\" : true, \"matchedCount\" : 1, \"modifiedCount\" : 1 }\n</code></pre> We can operate on different field on the same time, but we cannot set age and increment age at the same time. <p>We have other 3 operators like <code>$inc</code>. those are <code>$min</code>, <code>$max</code>, <code>$mul</code>.</p> <p>The field age will be updated as the max value between what we have passed and what is the previous value. If the previous value is 20 then the new value of age will be 31 but if its already 35 then the value will not be changed. </p><pre><code>db.infos.updateOne(\n    { name : \"Manual\" },\n    { $max :{ age : 31 }}\n)\n</code></pre> <p><code>$min</code> and <code>$max</code> is quite similar operation just that one is taking minimum value and another is taking maximum value. The <code>$mul</code> operator will multiply the field with the value that we have passed. If the previous value of age is 30 then the new value will be 30*1.1 = 33 </p><pre><code>db.infos.updateOne(\n    { name : \"Manual\" },\n    { $mul :{ age : 1.1 }}\n)\n</code></pre> <p>We can also drop any field with <code>$unset</code> operator. With this command we can remove the phone field. The value of phone here will be ignored. We can assign any value. </p><pre><code>db.infos.updateOne(\n    { name : \"Manuel\" },\n    { $unset :{ phone : \"\" }}\n)\n</code></pre> <p>We also can rename the field using the <code>$rename</code> operator. The field age will now be converted to <code>totalAge</code> </p><pre><code>db.infos.updateMany(\n    {},\n    { $rename :{ age : \"totalAge\" }}\n)\n\n{ \"acknowledged\" : true, \"matchedCount\" : 4, \"modifiedCount\" : 2 }\n</code></pre> <p>We can do <code>update</code> and <code>insert</code> operation at the same time, and it is called <code>upsert</code>.  Suppose we don\u2019t know we have a document with name as <code>Abhishek</code> or not and we also want to change its value if it is there.  So, we can use <code>upsert</code> here. So, to use <code>upsert</code> we must pass the <code>upsert</code> value in the last parameter.  By default, its value is true. </p><pre><code>&gt; db.infos.updateOne(\n    { name : \"Abhishek\" }, \n    { $set : \n        { \n            \"hobbies\": [\n            { \"title\": \"Sports\", \"frequency\": 3 },\n            { \"title\": \"Cooking\", \"frequency\": 6 }], \n            \"phone\": 131782734, \n            \"isSporty\": true \n        }\n    } , \n    { upsert : true }\n)\n\n\n{\n        \"acknowledged\" : true,\n        \"matchedCount\" : 0,\n        \"modifiedCount\" : 0,\n        \"upsertedId\" : ObjectId(\"62da1c2f60336bad54ef7227\")\n}\n</code></pre> MongoDB is smart enough to determine that if we are querying with equality operator then the name value must be there.  So, in the new object name, hobbies, phone, isSporty all these values will be present. <p>Array update operations:</p> <p>Suppose we have to find the documents where <code>hobbies</code> array has <code>title</code> value of <code>Sports</code> and <code>frequency</code> value greater than 3.  Then the query will be like. </p><pre><code>db.infos.find({ \n    hobbies : { \n        $elemMatch : { \n            title : \"Sports\" , \n            \"frequency\" : { $gte : 3}\n            }\n        }\n    }\n)\n{ \n    \"_id\" : ObjectId(\"62ac4ff719cc703713ba43be\"), \n    \"name\" : \"Chris\", \n    \"hobbies\" : [ \n        { \"title\" : \"Sports\", \"frequency\" : 5 }, \n        { \"title\" : \"Cooking\", \"frequency\" : 3 }, \n        { \"title\" : \"Hiking\", \"frequency\" : 1 } \n    ], \n    \"isSporty\" : true \n}\n{ \n    \"_id\" : ObjectId(\"62ac4ff719cc703713ba43c0\"), \n    \"name\" : \"Max\", \n    \"hobbies\" : [ \n        { \"title\" : \"Sports\", \"frequency\" : 3 }, \n        { \"title\" : \"Cooking\", \"frequency\" : 6 } \n    ], \n    \"phone\" : 131782734,\n    \"isSporty\" : true \n}\n{ \n    \"_id\" : ObjectId(\"62da1c2f60336bad54ef7227\"), \n    \"name\" : \"Abhishek\", \n    \"hobbies\" : [ \n        { \"title\" : \"Sports\", \"frequency\" : 3 }, \n        { \"title\" : \"Cooking\", \"frequency\" : 6 } \n    ],\n    \"isSporty\" : true, \n    \"phone\" : 131782734 \n}\n</code></pre> <p>Suppose we want to update the inner array document that we have found and highlighted above. </p><pre><code>&gt; db.infos.updateMany({ \n    hobbies : {\n        $elemMatch : { \n            title : \"Sports\" , \n            \"frequency\" : { $gte : 3}\n        }\n    }}, \n    { $set : { \n        \"hobbies.$.highFrequency\" : true \n    }}\n)\n{ \"acknowledged\" : true, \"matchedCount\" : 3, \"modifiedCount\" : 3 }\n</code></pre> This <code>$</code> represents the same element.  Here we are adding new field that is why we are using <code>\"hobbies.$.highFrequency\"</code> but if we want to override that document then we can simply do this <code>\"hobbies.$\" : {\"title\" : \"Sports\", \"frequency\" : 5}</code> <p>Suppose we want to update all the documents of the array. So, we can use $[] operator it means all the array documents. <code>goodHobby</code> field added for all the inner array documents. </p><pre><code>&gt; db.infos.updateMany({ \n    hobbies : { \n        $elemMatch : { title : \"Sports\" , \"frequency\" : { $gte : 3}}\n    }}, \n    { $set : { \"hobbies.$[].goodHobby\" : true }}\n)\n{ \"acknowledged\" : true, \"matchedCount\" : 3, \"modifiedCount\" : 3 }\n&gt; db.infos.find({ \n        hobbies : { \n            $elemMatch : { title : \"Sports\" , \"frequency\" : { $gte : 3}}\n        }}\n    ).pretty()\n{\n        \"_id\" : ObjectId(\"62ac4ff719cc703713ba43be\"),\n        \"name\" : \"Chris\",\n        \"hobbies\" : [\n                {\n                        \"title\" : \"Sports\",\n                        \"frequency\" : 5,\n                        \"highFrequency\" : true,\n                        \"goodHobby\" : true\n                },\n                {\n                        \"title\" : \"Cooking\",\n                        \"frequency\" : 3,\n                        \"goodHobby\" : true\n                },\n                {\n                        \"title\" : \"Hiking\",\n                        \"frequency\" : 1,\n                        \"goodHobby\" : true\n                }\n        ],\n        \"isSporty\" : true\n}\n</code></pre> <p>Let's say if we have a criterion to upadate only some certain documents then we can <code>$[ el ]</code> and later we will define the <code>el</code> condition in the thir parameter <code>arrayFilers</code> part. In array filter we can pass as many conditions as we want. </p><pre><code>&gt; db.infos.updateOne(\n    { name: \"Abhishek\"}, \n    { $set : { \"hobbies.$[el].goodFrequency\" : true}} , \n    { arrayFilters : [{ \"el.frequency\" :{ $gte : 3}} ]} \n)\n{ \"acknowledged\" : true, \"matchedCount\" : 1, \"modifiedCount\" : 1 }\n\n&gt; db.infos.find({name:\"Abhishek\"})\n{ \n    \"_id\" : ObjectId(\"62da1c2f60336bad54ef7227\"), \n    \"name\" : \"Abhishek\", \n    \"hobbies\" : [ \n        { \"title\" : \"Sports\", \"frequency\" : 3, \"highFrequency\" : true, \"goodHobby\" : true, \"goodFrequency\" : true }, \n        { \"title\" : \"Cooking\", \"frequency\" : 6, \"goodHobby\" : true, \"goodFrequency\" : true } \n    ], \n    \"isSporty\" : true, \n    \"phone\" : 131782734 \n}\n</code></pre> <p>We can also add new element in our array. With <code>$push</code> we can add new element to the existing array. </p><pre><code>&gt; db.infos.updateOne(\n    { name: \"Abhishek\"}, \n    { $push : \n        { hobbies : { title: \"Hiking\" , frequency : 1}}\n    } \n)\n{ \"acknowledged\" : true, \"matchedCount\" : 1, \"modifiedCount\" : 1 }\n\n&gt; db.infos.find({name:\"Abhishek\"})\n{ \n    \"_id\" : ObjectId(\"62da1c2f60336bad54ef7227\"), \n    \"name\" : \"Abhishek\", \n    \"hobbies\" : [ \n        { \"title\" : \"Sports\", \"frequency\" : 3, \"highFrequency\" : true, \"goodHobby\" : true, \"goodFrequency\" : true }, \n        { \"title\" : \"Cooking\", \"frequency\" : 6, \"goodHobby\" : true, \"goodFrequency\" : true }, \n        { \"title\" : \"Hiking\", \"frequency\" : 1 } \n    ], \n    \"isSporty\" : true, \n    \"phone\" : 131782734 \n}\n</code></pre> <p>We can also add more than one documents with <code>$each</code> operator. </p><pre><code>&gt; db.infos.updateOne(\n    { name: \"Abhishek\"}, \n    { $push : { \n        hobbies : { \n            $each : [\n                { title: \"Hiking\" , frequency : 1},\n                { title : \"wine\", frequecy: 1}\n            ]\n        }}\n    }\n)\n{ \"acknowledged\" : true, \"matchedCount\" : 1, \"modifiedCount\" : 1 }\n\n&gt; db.infos.find({name:\"Abhishek\"})\n{ \n    \"_id\" : ObjectId(\"62da1c2f60336bad54ef7227\"), \n    \"name\" : \"Abhishek\", \n    \"hobbies\" : [ \n        { \"title\" : \"Sports\", \"frequency\" : 3, \"highFrequency\" : true, \"goodHobby\" : true, \"goodFrequency\" : true }, \n        { \"title\" : \"Cooking\", \"frequency\" : 6, \"goodHobby\" : true, \"goodFrequency\" : true }, \n        { \"title\" : \"Hiking\", \"frequency\" : 1 }, \n        { \"title\" : \"Hiking\", \"frequency\" : 1 }, \n        { \"title\" : \"wine\", \"frequecy\" : 1 } \n    ], \n    \"isSporty\" : true, \n    \"phone\" : 131782734 \n}\n</code></pre> We can also add <code>sor</code>t or <code>slice</code> operator to <code>add</code> the element in sorted order or we can also take only one element. <p>But there is issue with <code>$push</code> operator.  If the values are already existing, then also it will add the value.  We can use <code>$addToSet</code> operator for to add <code>unique</code> element in the array. </p><pre><code>&gt; db.infos.updateOne(\n    { name: \"Abhishek\"}, \n    { $addToSet : { \n        hobbies : { \n            $each : [\n                { title: \"Hiking\" , frequency : 1},\n                {title : \"wine\", frequecy: 1}\n            ]\n        }}\n    }\n)\n{ \"acknowledged\" : true, \"matchedCount\" : 1, \"modifiedCount\" : 0 }\n\n&gt; db.infos.find({name:\"Abhishek\"})\n{ \n    \"_id\" : ObjectId(\"62da1c2f60336bad54ef7227\"), \n    \"name\" : \"Abhishek\", \n    \"hobbies\" : [ \n        { \"title\" : \"Sports\", \"frequency\" : 3, \"highFrequency\" : true, \"goodHobby\" : true, \"goodFrequency\" : true }, \n        { \"title\" : \"Cooking\", \"frequency\" : 6, \"goodHobby\" : true, \"goodFrequency\" : true }, \n        { \"title\" : \"Hiking\", \"frequency\" : 1 }, \n        { \"title\" : \"Hiking\", \"frequency\" : 1 }, \n        { \"title\" : \"wine\", \"frequecy\" : 1 } \n    ], \n    \"isSporty\" : true, \n    \"phone\" : 131782734 \n}\n\nWe can also pull the element from an array with `$pull` operator.\n```js\n&gt; db.infos.updateOne(\n        { name: \"Abhishek\"},\n        { $pull : { hobbies : { title : \"Hiking\" }}}\n    )\n{ \"acknowledged\" : true, \"matchedCount\" : 1, \"modifiedCount\" : 1 }\n\n&gt; db.infos.find({name:\"Abhishek\"})\n{ \n    \"_id\" : ObjectId(\"62da1c2f60336bad54ef7227\"), \n    \"name\" : \"Abhishek\", \n    \"hobbies\" : [ \n        { \"title\" : \"Sports\", \"frequency\" : 3, \"highFrequency\" : true, \"goodHobby\" : true, \"goodFrequency\" : true }, \n        { \"title\" : \"Cooking\", \"frequency\" : 6, \"goodHobby\" : true, \"goodFrequency\" : true }, \n        { \"title\" : \"wine\", \"frequecy\" : 1 } \n    ], \n    \"isSporty\" : true, \n    \"phone\" : 131782734 \n}\n</code></pre> <code>{ $pull : { hobbies : { title : \"Hiking\" }}}</code> it means pull from the hobbies array where title is Hiking. We can also add other queries. <p>If we want to remove the last element from the array, then we can use <code>$pop</code> operator with value of 1 and if we want to remove the first element then we can assign the value with -1. </p><pre><code>&gt; db.infos.find({name:\"Abhishek\"})\n{ \n    \"_id\" : ObjectId(\"62da1c2f60336bad54ef7227\"), \n    \"name\" : \"Abhishek\", \n    \"hobbies\" : [ \n        { \"title\" : \"Sports\", \"frequency\" : 3, \"highFrequency\" : true, \"goodHobby\" : true, \"goodFrequency\" : true }, \n        { \"title\" : \"Cooking\", \"frequency\" : 6, \"goodHobby\" : true, \"goodFrequency\" : true }, \n        { \"title\" : \"wine\", \"frequecy\" : 1 } \n    ], \n    \"isSporty\" : true, \n    \"phone\" : 131782734 \n}\n\n&gt; db.infos.updateOne(\n        { name: \"Abhishek\"}, \n        { $pop : { hobbies : 1}}\n    )\n{ \"acknowledged\" : true, \"matchedCount\" : 1, \"modifiedCount\" : 1 }\n\n&gt; db.infos.find({name:\"Abhishek\"})\n{ \n    \"_id\" : ObjectId(\"62da1c2f60336bad54ef7227\"), \n    \"name\" : \"Abhishek\", \n    \"hobbies\" : [ \n        { \"title\" : \"Sports\", \"frequency\" : 3, \"highFrequency\" : true, \"goodHobby\" : true, \"goodFrequency\" : true }, \n        { \"title\" : \"Cooking\", \"frequency\" : 6, \"goodHobby\" : true, \"goodFrequency\" : true } \n    ], \n    \"isSporty\" : true, \n    \"phone\" : 131782734 \n}\n\n&gt; db.infos.updateOne(\n        { name: \"Abhishek\"}, \n        { $pop : { hobbies : -1}}\n    )\n{ \"acknowledged\" : true, \"matchedCount\" : 1, \"modifiedCount\" : 1 }\n\n&gt; db.infos.find({name:\"Abhishek\"})\n{ \n    \"_id\" : ObjectId(\"62da1c2f60336bad54ef7227\"), \n    \"name\" : \"Abhishek\", \n    \"hobbies\" : [ \n        { \"title\" : \"Cooking\", \"frequency\" : 6, \"goodHobby\" : true, \"goodFrequency\" : true } \n    ], \n    \"isSporty\" : true, \n    \"phone\" : 131782734 \n}\n</code></pre>"},{"location":"mongodb/update/#more-examples","title":"More examples","text":""},{"location":"mongodb/update/#basic-updates","title":"Basic Updates","text":"<pre><code>db.coll.updateOne({\"_id\": 1}, {$set: {\"year\": 2016, name: \"Max\"}})\ndb.coll.updateOne({\"_id\": 1}, {$unset: {\"year\": 1}})\ndb.coll.updateOne({\"_id\": 1}, {$rename: {\"year\": \"date\"} })\ndb.coll.updateOne({\"_id\": 1}, {$inc: {\"year\": 5}})\ndb.coll.updateOne({\"_id\": 1}, {$mul: {price: NumberDecimal(\"1.25\"), qty: 2}})\ndb.coll.updateOne({\"_id\": 1}, {$min: {\"imdb\": 5}})\ndb.coll.updateOne({\"_id\": 1}, {$max: {\"imdb\": 8}})\ndb.coll.updateOne({\"_id\": 1}, {$currentDate: {\"lastModified\": true}})\ndb.coll.updateOne({\"_id\": 1}, {$currentDate: {\"lastModified\": {$type: \"timestamp\"}}})\n</code></pre>"},{"location":"mongodb/update/#array-updates","title":"Array Updates","text":"<pre><code>db.coll.updateOne({\"_id\": 1}, {$push :{\"array\": 1}})\ndb.coll.updateOne({\"_id\": 1}, {$pull :{\"array\": 1}})\ndb.coll.updateOne({\"_id\": 1}, {$addToSet :{\"array\": 2}})\ndb.coll.updateOne({\"_id\": 1}, {$pop: {\"array\": 1}})  // last element\ndb.coll.updateOne({\"_id\": 1}, {$pop: {\"array\": -1}}) // first element\ndb.coll.updateOne({\"_id\": 1}, {$pullAll: {\"array\" :[3, 4, 5]}})\ndb.coll.updateOne({\"_id\": 1}, {$push: {\"scores\": {$each: [90, 92]}}})\ndb.coll.updateOne({\"_id\": 2}, {$push: {\"scores\": {$each: [40, 60], $sort: 1}}}) // array sorted\ndb.coll.updateOne({\"_id\": 1, \"grades\": 80}, {$set: {\"grades.$\": 82}})\ndb.coll.updateMany({}, {$inc: {\"grades.$[]\": 10}})\ndb.coll.updateMany({}, {$set: {\"grades.$[element]\": 100}}, {multi: true, arrayFilters: [{\"element\": {$gte: 100}}]})\n</code></pre>"},{"location":"mongodb/update/#findoneandupdate","title":"FindOneAndUpdate","text":"<pre><code>db.coll.findOneAndUpdate({\"name\": \"Max\"}, {$inc: {\"points\": 5}}, {returnNewDocument: true})\n</code></pre>"},{"location":"mongodb/update/#upsert","title":"Upsert","text":"<pre><code>db.coll.updateOne({\"_id\": 1}, {$set: {item: \"apple\"}, $setOnInsert: {defaultQty: 100}}, {upsert: true})\n</code></pre>"},{"location":"mongodb/update/#replace","title":"Replace","text":"<pre><code>db.coll.replaceOne({\"name\": \"Max\"}, {\"firstname\": \"Maxime\", \"surname\": \"Beugnet\"})\n</code></pre>"},{"location":"mongodb/update/#write-concern","title":"Write Concern","text":"<pre><code>db.coll.updateMany({}, {$set: {\"x\": 1}}, {\"writeConcern\": {\"w\": \"majority\", \"wtimeout\": 5000}})\n</code></pre>"},{"location":"neo4j/links/","title":"links","text":""},{"location":"neo4j/links/#neo4j-basics","title":"neo4j basics","text":""},{"location":"neo4j/links/#website","title":"Website","text":""},{"location":"neo4j/links/#official-documentation","title":"Official documentation","text":"<ul> <li>Querying with Cypher</li> <li>Core concepts</li> </ul>"},{"location":"neo4j/links/#neo4j-migrations","title":"neo4j migrations","text":"<ul> <li>official documentation</li> <li>Migrating Neo4J graph schemas in managed Kubernetes</li> </ul>"},{"location":"neo4j/links/#youtube","title":"Youtube","text":"<ul> <li>Intro to Graph Databases Series</li> <li>Neo4j Course for Beginners</li> </ul>"},{"location":"postgres/links/","title":"links","text":""},{"location":"postgres/links/#postgres-basic","title":"POSTGRES basic","text":""},{"location":"postgres/links/#website","title":"Website","text":"<ul> <li>How to Deploy Postgres on Kubernetes for a Scalable Web Application</li> <li>Kubernetes - Configure PostgreSQL Streaming Replication</li> </ul>"},{"location":"postgres/links/#youtube","title":"Youtube","text":"<ul> <li>I replaced my entire tech stack with Postgres...</li> <li>5 Secrets for making PostgreSQL run BLAZING FAST. How to improve database performance.</li> <li>Solving one of PostgreSQL's biggest weaknesses.</li> <li>Wait... PostgreSQL can do WHAT?</li> <li>Learn PostgreSQL Tutorial - Full Course for Beginners</li> <li>PostgresSQL</li> <li> <p>High-Performance Programming</p> <ul> <li>PostgreSQL High-Availability</li> <li>PostgreSQL Perfomance Tuning</li> <li>MySQL Performance Tuning</li> </ul> </li> <li> <p>Why Postgres Is So Popular</p> </li> <li>Postgres Architecture Explained</li> <li>PostgreSQL Perfomance Tuning | High-Performance Programming</li> <li>PostgreSQL High-Availability | High-Performance Programming</li> </ul>"},{"location":"postgres/links/#udemy","title":"Udemy","text":"<ul> <li>SQL and PostgreSQL: The Complete Developer's Guide</li> <li>PostgreSQL Bootcamp : Go From Beginner to Advanced, 60+hours</li> </ul>"},{"location":"redis/introduction/","title":"introduction","text":""},{"location":"redis/introduction/#redis","title":"Redis","text":"<p>Redis (Remote Dictionary Server) is an open source, in-memory, NoSQL key/value store that is used primarily as an application cache or quick-response database</p>"},{"location":"redis/introduction/#redis-datatypes","title":"Redis datatypes","text":""},{"location":"redis/links/","title":"links","text":""},{"location":"redis/links/#redis-basics","title":"Redis basics","text":""},{"location":"redis/links/#resources","title":"Resources","text":"<ul> <li>introduction</li> </ul>"},{"location":"redis/links/#youtube","title":"Youtube","text":""},{"location":"redis/links/#introduction","title":"Introduction","text":"<ul> <li>System Design: Why is single-threaded Redis so fast?</li> <li>Top 5 Redis Use Cases</li> <li>Can Redis be used as a Primary database?</li> <li>Redis Crash Course - the What, Why and How to use Redis as your primary database</li> <li>I've been using Redis wrong this whole time...</li> <li>Stop Using Redis. Use Open Source Instead Valkey</li> </ul>"},{"location":"redis/links/#tutorial","title":"Tutorial","text":"<ul> <li>Redis Crash Course</li> <li>Learn Redis in ONE video</li> <li>Redis Enterprise Cloud</li> </ul>"},{"location":"redis/links/#playlist","title":"Playlist","text":"<ul> <li>redis personal</li> </ul>"},{"location":"redis/links/#udemy","title":"Udemy","text":"<ul> <li>Modern Redis Unleashed</li> <li>Redis Beginners to Advance With Free Lab</li> <li>Redis: The Complete Developer's Guide</li> </ul>"},{"location":"sql/leetcode/","title":"leetcode","text":""},{"location":"sql/leetcode/#resources","title":"Resources","text":"<p>Leetcode 50 sql problem link</p> <p>Crack SQL Interview in 50 Qs link</p>"},{"location":"sql/leetcode/#questions","title":"Questions","text":""},{"location":"sql/leetcode/#select","title":"Select","text":"<ul> <li>Recyclable and Low Fat Products</li> <li>Find Customer Referee</li> <li>Big Countries</li> <li>Article Views I</li> <li>Invalid Tweets</li> </ul>"},{"location":"sql/leetcode/#basic-joins","title":"Basic Joins","text":"<ul> <li>Replace Employee ID With The Unique Identifier</li> </ul>"},{"location":"sql/links/","title":"sql-helper","text":""},{"location":"surrielDB/links/","title":"links","text":""},{"location":"surrielDB/links/#surrieldb-basics","title":"SurrielDB basics","text":""},{"location":"surrielDB/links/#youtube","title":"Youtube","text":""},{"location":"surrielDB/links/#introduction","title":"Introduction","text":"<ul> <li>SurrealDB in 100 Seconds</li> <li>Beyond Surreal? A closer look at NewSQL Relational Data</li> <li>Rust Powered Database SurrealDB (It's Pretty Ambitious)</li> <li>SurrealDB - Rust Embedded Database - Quick Tutorial</li> </ul>"}]}